{"cells":[{"cell_type":"markdown","metadata":{"id":"lLqJy6EZtrZB"},"source":["### Setup"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"7-ewruGCyaCn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702446719229,"user_tz":420,"elapsed":2211,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"125afb25-9e3d-469e-fd63-c41a5e319258"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"yLRvBRGgt5Zk"},"source":["#### Install Pytorch Geometric Temporal"]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"id":"QRkM-wvTVBMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702446724528,"user_tz":420,"elapsed":5301,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"90ec9318-8ae4-44f2-a2e2-c523429e449f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"oiSS4wuxZ01m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702446729930,"user_tz":420,"elapsed":5406,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"799ea451-61f9-457d-e106-cd0929ce0974"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n","Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.3.1+pt21cu118)\n","Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cu118)\n","Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cu118)\n","Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cu118)\n","Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cu118)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n"]}],"source":["import torch\n","\n","TORCH = torch.__version__.split('+')[0]\n","CUDA = 'cu' + torch.version.cuda.replace('.', '')\n","\n","# Construct the installation command\n","install_command = f\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\"\n","\n","# Execute the command\n","!{install_command}"]},{"cell_type":"code","source":["import numpy as np\n","import os\n","\n","# Set a random seed for reproducibility\n","torch.manual_seed(42)\n","np.random.seed(42)\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"upFSRna0XWWE","executionInfo":{"status":"ok","timestamp":1702446729930,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["### `ASLInMemoryDataset` Class"],"metadata":{"id":"m-cInrk0XkXz"}},{"cell_type":"code","source":["import json\n","from itertools import repeat\n","from torch_geometric.data import InMemoryDataset, Data\n","from tqdm.notebook import tqdm\n","from torch_geometric.data import Data\n","from torch_geometric.utils import add_self_loops, remove_self_loops\n","\n","class ASLInMemoryDataset(InMemoryDataset):\n","    def __init__(self, root, transform=None, pre_transform=None):\n","        super(ASLInMemoryDataset, self).__init__(root, transform, pre_transform)\n","        self.data, self.slices = torch.load(self.processed_paths[0])\n","        self.sign_to_label_map, self.total_num_classes = self._load_metadata()\n","\n","    def _save_metadata(self, sign_to_label_map, total_num_classes):\n","        metadata_path = os.path.join(self.processed_dir, 'metadata.pt')\n","        torch.save({'sign_to_label_map': sign_to_label_map, 'total_num_classes': total_num_classes}, metadata_path)\n","\n","    def _load_metadata(self):\n","        metadata_path = os.path.join(self.processed_dir, 'metadata.pt')\n","        if os.path.exists(metadata_path):\n","            metadata = torch.load(metadata_path)\n","            return metadata.get('sign_to_label_map', {}), metadata.get('total_num_classes', 0)\n","        return {}, 0\n","\n","    @property\n","    def raw_file_names(self):\n","        return [os.path.splitext(filename)[0] for filename in os.listdir(self.raw_dir)]\n","\n","    @property\n","    def processed_file_names(self):\n","        return ['processed_data.pt']\n","\n","    def download(self):\n","        # We're using local files, so no need to implement download logic\n","        pass\n","\n","    def process(self):\n","        data_list = []\n","\n","        loader = ASLDatasetLoader(self.raw_dir)\n","        self._sign_to_label = loader.sign_to_label\n","        dataset = loader.get_dataset()\n","\n","        # If you want to add a progress bar, use tqdm here\n","        # dataset = tqdm(dataset, desc=\"Processing dataset\", leave=False)\n","\n","        data_list.extend(dataset)\n","\n","        if self.pre_filter is not None:\n","            data_list = [data for data in data_list if self.pre_filter(data)]\n","\n","        if self.pre_transform is not None:\n","            data_list = [self.pre_transform(data) for data in data_list]\n","\n","        data, slices = self.collate(data_list)\n","        torch.save((data, slices), self.processed_paths[0])\n","\n","        # After processing, save the sign_to_label and num_classes\n","        self._save_metadata(loader.sign_to_label, loader.number_of_classes())\n","\n","    def len(self):\n","        return len(self._data.y)\n","\n","    def get(self, idx):\n","        data = Data()\n","        for key in self._data.keys():\n","            item, slices = self._data[key], self.slices[key]\n","            s = list(repeat(slice(None), item.dim()))\n","            s[self._data.__cat_dim__(key, item)] = slice(slices[idx], slices[idx + 1])\n","            data[key] = item[s]\n","        return data\n","\n","    def sign_to_label(self):\n","        return self.sign_to_label_map"],"metadata":{"id":"EgWHOt3SXmCj","executionInfo":{"status":"ok","timestamp":1702446729930,"user_tz":420,"elapsed":9,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zi7c7EMpsCBX"},"source":["### `ASLDatasetLoader` Class\n","\n","The `ASLDatasetLoader` class is designed for loading and processing the ASL dataset. Given a directory, it reads sign language data from JSON files and constructs graph representations suitable for graph-based neural networks. Crucially, the class converts JSON data into PyTorch Geometric (PyG) `Data` objects comprising `x` (node features), `edge_index` (graph connectivity), and `y' (labels) attributes.\n","\n","**Methods**:\n","\n","- `_create_sign_to_label_map`: Generates a mapping from sign names to unique labels.\n","\n","- `_read_file_data`: Reads data from a given JSON file.\n","\n","- `_augment_data`: Implements data augmentation by applying random rotation, translation, and scaling to landmarks, which can enhance the model's robustness.\n","\n","- `_create_graph_from_frame`: Constructs a PyG `Data` object from frame data, concentrating on hand and face landmarks. Edges are created between consecutive landmarks and between left and right hand landmarks. Additional features, like hand-to-face distances, are also computed.\n","\n","- `get_dataset`: Assembles the dataset, optionally incorporating data augmentation. The function outputs a list of PyG `Data` objects ready for graph neural network processing."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"LifBvD3D4t4C","executionInfo":{"status":"ok","timestamp":1702446729931,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["class ASLDatasetLoader:\n","    # Define natural connections as class attributes\n","    HAND_CONNECTIONS = frozenset([\n","      # Left hand palm\n","      (\"left_hand-0\", \"left_hand-1\"),\n","      (\"left_hand-0\", \"left_hand-5\"),\n","      (\"left_hand-9\", \"left_hand-13\"),\n","      (\"left_hand-13\", \"left_hand-17\"),\n","      (\"left_hand-5\", \"left_hand-9\"),\n","      (\"left_hand-0\", \"left_hand-17\"),\n","      # Left hand thumb\n","      (\"left_hand-1\", \"left_hand-2\"),\n","      (\"left_hand-2\", \"left_hand-3\"),\n","      (\"left_hand-3\", \"left_hand-4\"),\n","      # Left hand index finger\n","      (\"left_hand-5\", \"left_hand-6\"),\n","      (\"left_hand-6\", \"left_hand-7\"),\n","      (\"left_hand-7\", \"left_hand-8\"),\n","      # Left hand middle finger\n","      (\"left_hand-9\", \"left_hand-10\"),\n","      (\"left_hand-10\", \"left_hand-11\"),\n","      (\"left_hand-11\", \"left_hand-12\"),\n","      # Left hand ring finger\n","      (\"left_hand-13\", \"left_hand-14\"),\n","      (\"left_hand-14\", \"left_hand-15\"),\n","      (\"left_hand-15\", \"left_hand-16\"),\n","      # Left hand pinky\n","      (\"left_hand-17\", \"left_hand-18\"),\n","      (\"left_hand-18\", \"left_hand-19\"),\n","      (\"left_hand-19\", \"left_hand-20\"),\n","      # Right hand palm\n","      (\"right_hand-0\", \"right_hand-1\"),\n","      (\"right_hand-0\", \"right_hand-5\"),\n","      (\"right_hand-9\", \"right_hand-13\"),\n","      (\"right_hand-13\", \"right_hand-17\"),\n","      (\"right_hand-5\", \"right_hand-9\"),\n","      (\"right_hand-0\", \"right_hand-17\"),\n","      # Right hand thumb\n","      (\"right_hand-1\", \"right_hand-2\"),\n","      (\"right_hand-2\", \"right_hand-3\"),\n","      (\"right_hand-3\", \"right_hand-4\"),\n","      # Right hand index finger\n","      (\"right_hand-5\", \"right_hand-6\"),\n","      (\"right_hand-6\", \"right_hand-7\"),\n","      (\"right_hand-7\", \"right_hand-8\"),\n","      # Right hand middle finger\n","      (\"right_hand-9\", \"right_hand-10\"),\n","      (\"right_hand-10\", \"right_hand-11\"),\n","      (\"right_hand-11\", \"right_hand-12\"),\n","      # Right hand ring finger\n","      (\"right_hand-13\", \"right_hand-14\"),\n","      (\"right_hand-14\", \"right_hand-15\"),\n","      (\"right_hand-15\", \"right_hand-16\"),\n","      # Right hand pinky\n","      (\"right_hand-17\", \"right_hand-18\"),\n","      (\"right_hand-18\", \"right_hand-19\"),\n","      (\"right_hand-19\", \"right_hand-20\"),\n","    ])\n","\n","    POSE_CONNECTIONS = frozenset([\n","      (\"pose-0\", \"pose-1\"),\n","      (\"pose-1\", \"pose-2\"),\n","      (\"pose-2\", \"pose-3\"),\n","      (\"pose-3\", \"pose-7\"),\n","      (\"pose-0\", \"pose-4\"),\n","      (\"pose-4\", \"pose-5\"),\n","      (\"pose-5\", \"pose-6\"),\n","      (\"pose-6\", \"pose-8\"),\n","      (\"pose-9\", \"pose-10\"),\n","      (\"pose-11\", \"pose-12\"),\n","      (\"pose-11\", \"pose-13\"),\n","      (\"pose-13\", \"pose-15\"),\n","      (\"pose-15\", \"pose-17\"),\n","      (\"pose-12\", \"pose-14\"),\n","      (\"pose-14\", \"pose-16\"),\n","      (\"pose-16\", \"pose-18\"),\n","      (\"pose-11\", \"pose-23\"),\n","      (\"pose-12\", \"pose-24\"),\n","      (\"pose-23\", \"pose-24\"),\n","    ])\n","\n","    FACE_CONNECTIONS = frozenset([\n","      # Connections for FACEMESH_LIPS using available landmarks\n","      (\"face-61\", \"face-146\"), (\"face-146\", \"face-91\"), (\"face-91\", \"face-181\"),\n","      (\"face-181\", \"face-84\"), (\"face-84\", \"face-17\"), (\"face-17\", \"face-314\"),\n","      (\"face-314\", \"face-405\"), (\"face-405\", \"face-321\"), (\"face-321\", \"face-375\"),\n","      (\"face-375\", \"face-291\"), (\"face-78\", \"face-95\"), (\"face-95\", \"face-88\"),\n","      (\"face-88\", \"face-178\"), (\"face-178\", \"face-87\"), (\"face-87\", \"face-14\"),\n","      (\"face-14\", \"face-317\"), (\"face-317\", \"face-402\"), (\"face-402\", \"face-318\"),\n","      (\"face-318\", \"face-324\"), (\"face-324\", \"face-308\"),\n","\n","      # Connections for FACEMESH_LEFT_EYE using available landmarks\n","      (\"face-263\", \"face-249\"), (\"face-388\", \"face-387\"), (\"face-387\", \"face-386\"),\n","      (\"face-386\", \"face-385\"), (\"face-385\", \"face-384\"), (\"face-384\", \"face-398\"),\n","\n","      # Connections for FACEMESH_LEFT_EYEBROW using available landmarks\n","      (\"face-276\", \"face-283\"), (\"face-300\", \"face-293\"), (\"face-293\", \"face-334\"),\n","      (\"face-334\", \"face-296\"), (\"face-296\", \"face-336\"),\n","\n","      # Connections for FACEMESH_RIGHT_EYE using available landmarks\n","      (\"face-33\", \"face-7\"), (\"face-246\", \"face-161\"), (\"face-161\", \"face-160\"),\n","      (\"face-160\", \"face-159\"), (\"face-159\", \"face-158\"), (\"face-158\", \"face-157\"),\n","      (\"face-157\", \"face-173\"),\n","\n","      # Connections for FACEMESH_RIGHT_EYEBROW using available landmarks\n","      (\"face-46\", \"face-53\"), (\"face-70\", \"face-63\"), (\"face-63\", \"face-105\"),\n","      (\"face-105\", \"face-66\"), (\"face-66\", \"face-107\"),\n","\n","      # Connections for FACEMESH_FACE_OVAL using available landmarks\n","      (\"face-10\", \"face-338\"), (\"face-338\", \"face-297\"), (\"face-297\", \"face-332\"),\n","      (\"face-332\", \"face-284\"), (\"face-284\", \"face-251\"), (\"face-251\", \"face-389\"),\n","      (\"face-389\", \"face-356\"), (\"face-356\", \"face-454\"), (\"face-454\", \"face-323\"),\n","      (\"face-323\", \"face-361\"), (\"face-361\", \"face-288\"), (\"face-288\", \"face-397\"),\n","      (\"face-397\", \"face-365\"), (\"face-365\", \"face-379\"), (\"face-379\", \"face-378\"),\n","      (\"face-378\", \"face-400\"), (\"face-400\", \"face-377\"), (\"face-377\", \"face-152\"),\n","      (\"face-152\", \"face-148\"), (\"face-148\", \"face-176\"), (\"face-176\", \"face-149\"),\n","      (\"face-149\", \"face-150\"), (\"face-150\", \"face-136\"), (\"face-136\", \"face-172\"),\n","      (\"face-172\", \"face-58\"), (\"face-58\", \"face-132\"), (\"face-132\", \"face-93\"),\n","      (\"face-93\", \"face-234\"), (\"face-234\", \"face-127\"), (\"face-127\", \"face-162\"),\n","      (\"face-162\", \"face-21\"), (\"face-21\", \"face-54\"), (\"face-54\", \"face-103\"),\n","      (\"face-103\", \"face-67\"), (\"face-67\", \"face-109\"), (\"face-109\", \"face-10\"),\n","    ])\n","\n","    def __init__(self, directory_path, min_examples_per_class=2, max_files=-1):\n","        self.directory_path = directory_path\n","        self.min_examples_per_class = min_examples_per_class\n","        self.max_files = max_files\n","        self.sign_to_label = self._create_sign_to_label_map()\n","\n","    def _create_sign_to_label_map(self):\n","        signs = [os.path.splitext(filename)[0] for filename in os.listdir(self.directory_path)]\n","        return {sign: i for i, sign in enumerate(signs)}\n","\n","    def _read_file_data(self, file_path):\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","\n","        sign_name = data[\"sign\"]\n","        num_examples = len(data[\"examples\"])\n","        print(f\"Loaded sign '{sign_name}' with {num_examples} examples\")\n","\n","        return data if num_examples >= self.min_examples_per_class else None\n","\n","    def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1, jittering_range=0.01, noise_scale=0.01, mirroring=False):\n","        \"\"\"\n","        Augment the frame data with various techniques including rotation, translation, scaling, jittering, noise injection, and mirroring.\n","\n","        :param frame_data: Dictionary containing frame landmarks and deltas.\n","        :param rotation_range: Maximum rotation angle in degrees.\n","        :param translation_range: Maximum translation as a fraction of landmark range.\n","        :param scaling_range: Maximum scaling factor.\n","        :param jittering_range: Range for jittering.\n","        :param noise_scale: Scale of the random noise to be added.\n","        :param mirroring: Whether to mirror the landmarks (simulate opposite hand).\n","        :return: Augmented frame data.\n","        \"\"\"\n","        # Extract landmarks\n","        landmarks = np.array([[landmark['x'], landmark['y']] for landmark in frame_data['landmarks']])\n","        centroid = np.mean(landmarks, axis=0)\n","\n","        # Jittering\n","        jittering = np.random.uniform(-jittering_range, jittering_range, landmarks.shape)\n","        landmarks += jittering\n","\n","        # Random rotation\n","        theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n","        rotation_matrix = np.array([\n","            [np.cos(theta), -np.sin(theta)],\n","            [np.sin(theta), np.cos(theta)]\n","        ])\n","        landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n","\n","        # Random translation\n","        max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n","        translations = np.random.uniform(-max_translation, max_translation, size=landmarks.shape[1])\n","        landmarks += translations\n","\n","        # Random scaling\n","        scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n","        landmarks = centroid + scale * (landmarks - centroid)\n","\n","        # Noise Injection\n","        noise = np.random.normal(0, noise_scale, landmarks.shape)\n","        landmarks += noise\n","\n","        # Mirroring (if applicable)\n","        if mirroring:\n","            landmarks[:, 0] = -landmarks[:, 0] + 2 * centroid[0]  # Reflect x-coordinates\n","\n","        # Update the landmarks in frame_data\n","        for i, landmark in enumerate(frame_data['landmarks']):\n","            landmark['x'], landmark['y'] = landmarks[i]\n","\n","        return frame_data\n","\n","\n","    def _create_graph_from_frame(self, sign_name, sign_data):\n","        graphs = []\n","\n","        for example in sign_data[\"examples\"]:\n","            all_features = []  # Combined list for landmarks, velocities, and accelerations\n","            edges = []\n","\n","            for frame in example[\"frames\"]:\n","                for landmark_data in frame[\"landmarks\"]:\n","                    # Extract spatial coordinates\n","                    landmark_features = [landmark_data[\"x\"], landmark_data[\"y\"]]\n","\n","                    # Extract temporal data (velocity and acceleration)\n","                    temporal_data = next((item for item in frame[\"temporal\"] if item[\"landmark\"] == landmark_data[\"landmark\"]), None)\n","                    if temporal_data:\n","                        velocity = [temporal_data[\"velocity\"][\"x\"], temporal_data[\"velocity\"][\"y\"]]\n","                        acceleration = [temporal_data[\"acceleration\"][\"x\"], temporal_data[\"acceleration\"][\"y\"]]\n","                    else:\n","                        velocity = [0, 0]\n","                        acceleration = [0, 0]\n","\n","                    # Combine spatial and temporal features\n","                    combined_features = landmark_features + velocity + acceleration\n","                    all_features.append(combined_features)\n","\n","                # Add spatial edges within the frame using natural connections\n","                for i in range(len(frame[\"landmarks\"])):\n","                    for j in range(len(frame[\"landmarks\"])):\n","                        if i != j:\n","                            connection = (frame[\"landmarks\"][i][\"landmark\"], frame[\"landmarks\"][j][\"landmark\"])\n","                            if connection in self.HAND_CONNECTIONS or \\\n","                              connection in self.POSE_CONNECTIONS or \\\n","                              connection in self.FACE_CONNECTIONS:\n","                                edges.append([len(all_features) - len(frame[\"landmarks\"]) + i,\n","                                              len(all_features) - len(frame[\"landmarks\"]) + j])\n","\n","            # Add temporal edges between frames within each example\n","            for i in range(len(example[\"frames\"]) - 1):\n","                for j in range(len(frame[\"landmarks\"])):\n","                    start_index = i * len(frame[\"landmarks\"]) + j\n","                    end_index = (i + 1) * len(frame[\"landmarks\"]) + j\n","                    edges.append([start_index, end_index])\n","\n","            # Create the graph\n","            x = torch.tensor(all_features, dtype=torch.float)\n","            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n","            y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n","\n","            # Append the graph for the current example to the list of graphs\n","            graphs.append(Data(x=x, edge_index=edge_index, y=y))\n","\n","        return graphs\n","\n","    def get_dataset(self):\n","        dataset = []\n","        file_count = 0\n","\n","        for filename in os.listdir(self.directory_path):\n","            if 0 <= self.max_files <= file_count:\n","                break  # Stop if max_files limit is reached\n","\n","            sign_name = os.path.splitext(filename)[0]\n","            file_path = os.path.join(self.directory_path, filename)\n","            sign_data = self._read_file_data(file_path)\n","            file_count += 1\n","\n","            if sign_data is None:\n","                print(f\"Skipping sign '{sign_name}' due to insufficient examples\")\n","                continue\n","\n","            # Retrieve a list of graphs, one for each example\n","            graphs = self._create_graph_from_frame(sign_name, sign_data)\n","\n","            # Debugging: Check the number of graphs created for the current sign\n","            print(f\"Sign '{sign_name}': Created {len(graphs)} graphs\")\n","\n","            dataset.extend(graphs)  # Extend the dataset with the list of graphs\n","\n","        return dataset\n","\n","    def number_of_classes(self):\n","        return len(self.sign_to_label)"]},{"cell_type":"markdown","metadata":{"id":"xooW2sogtdL1"},"source":["### `ASLGraphClassifier` Class\n","\n","The `ASLGraphClassifier`, features deeper GCN layers and additional channels to capture intricate data patterns potentially. It takes a PyG `Data` object as input, and its forward pass emits class logits.\n","\n","**Methods**:\n","\n","- `forward`: Details the forward pass, accepting a PyG `Data` object. Two GCN layers with subsequent batch normalization and dropout layers process the input. Post global max-pooling, two linear layers coupled with dropout ensure final classification, leading to log-softmax outputs."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RAslUK79VVV6","executionInfo":{"status":"ok","timestamp":1702446729931,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, BatchNorm, global_max_pool, LayerNorm\n","\n","class ASLGraphClassifier(torch.nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(ASLGraphClassifier, self).__init__()\n","        self.conv1 = GCNConv(num_features, 512)\n","        self.bn1 = BatchNorm(512)\n","        self.conv2 = GCNConv(512, 1024)\n","        self.bn2 = BatchNorm(1024)\n","        self.ln1 = LayerNorm(1024)  # Layer normalization\n","        self.lin1 = torch.nn.Linear(1024, 512)\n","        self.ln2 = LayerNorm(512)  # Layer normalization\n","        self.lin2 = torch.nn.Linear(512, num_classes)\n","\n","        self.dropout = torch.nn.Dropout(p=0.7)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        x = self.dropout(x)\n","        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n","        x = self.ln1(x)  # Apply layer normalization\n","        x = self.dropout(x)\n","\n","        x = global_max_pool(x, batch)\n","\n","        x = F.relu(self.lin1(x))\n","        x = self.ln2(x)  # Apply layer normalization\n","        x = self.dropout(x)\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","source":["import datetime\n","\n","CHECKPOINT_DIR = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints\"\n","\n","def save_checkpoint(model, optimizer, epoch, loss):\n","    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint-{timestamp}-epoch-{epoch}.pth\")\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss,\n","    }, checkpoint_path)\n","    print(f\"Checkpoint saved: {checkpoint_path}\")\n","\n","def load_latest_checkpoint(model, optimizer):\n","    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.pth')]\n","    if not checkpoints:\n","        return 0  # No checkpoint found\n","\n","    latest_checkpoint = max(checkpoints, key=lambda f: os.path.getmtime(os.path.join(CHECKPOINT_DIR, f)))\n","    checkpoint_path = os.path.join(CHECKPOINT_DIR, latest_checkpoint)\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    print(f\"Resuming from checkpoint: {checkpoint_path}\")\n","    return epoch"],"metadata":{"id":"lUjQnKTqUa7p","executionInfo":{"status":"ok","timestamp":1702446729931,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"RdBGsFveWcbF","executionInfo":{"status":"ok","timestamp":1702446730145,"user_tz":420,"elapsed":224,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch_geometric.loader import DataLoader\n","from collections import Counter\n","\n","def stratified_data_split(data_list, test_size=0.2):\n","    labels = [data.y.item() for data in data_list]\n","    train_data, test_data = train_test_split(data_list, test_size=test_size, stratify=labels, random_state=42)\n","    return train_data, test_data\n","\n","def validate(loader, model, device):\n","    model.eval()\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        with torch.no_grad():\n","            out = model(data)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == data.y).sum())\n","    return correct / len(loader.dataset)\n","\n","def train(train_dataset, test_dataset, num_classes=6, EPOCHS=100, LEARNING_RATE=0.001):\n","    train_labels = [data.y.item() for data in train_dataset]\n","    test_labels = [data.y.item() for data in test_dataset]\n","\n","    print(\"Training label distribution:\", Counter(train_labels))\n","    print(\"Test label distribution:\", Counter(test_labels))\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    num_features = train_dataset[0].x.size(1)\n","    model = ASLGraphClassifier(num_features=num_features, num_classes=num_classes).to(device)\n","\n","    initial_batch_size = 64\n","    final_batch_size = 16\n","    warmup_epochs = 5\n","    initial_lr = 0.00001\n","    validate_every_n_batches = 60\n","    patience=15\n","    weight_decay=1e-5\n","    reduction_factor=0.8\n","\n","    current_batch_size = initial_batch_size\n","    train_loader = DataLoader(train_dataset, batch_size=current_batch_size, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=weight_decay)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=patience, verbose=True)\n","\n","    l1_lambda = 1e-6\n","    l2_lambda = 1e-5\n","\n","    best_val_accuracy = 0\n","    epochs_without_improvement = 0\n","    max_epochs_without_improvement = 5\n","\n","    model.train()\n","    start_epoch = load_latest_checkpoint(model, optimizer)\n","    for epoch in range(start_epoch, EPOCHS):\n","        total_loss = 0\n","        correct_train = 0\n","        total_train = 0\n","        batch_count = 0\n","\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            out = model(batch)\n","\n","            l1_reg = sum(param.abs().sum() for param in model.parameters())\n","            l2_reg = sum(param.pow(2).sum() for param in model.parameters())\n","            loss = F.nll_loss(out, batch.y) + l1_lambda * l1_reg + l2_lambda * l2_reg\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            pred_train = out.argmax(dim=1)\n","            correct_train += int((pred_train == batch.y).sum())\n","            total_train += batch.y.size(0)\n","\n","            batch_count += 1\n","            if batch_count % validate_every_n_batches == 0:\n","                val_accuracy = validate(test_loader, model, device)\n","                print(f\"Validation Accuracy after {batch_count} batches: {val_accuracy:.4f}\")\n","\n","        if epoch < warmup_epochs:\n","            lr = initial_lr + (LEARNING_RATE - initial_lr) * (epoch / warmup_epochs)\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","\n","        if epoch % 10 == 0 and current_batch_size > final_batch_size:\n","            current_batch_size //= 2\n","            train_loader = DataLoader(train_dataset, batch_size=current_batch_size, shuffle=True)\n","\n","        avg_loss = total_loss / len(train_loader)\n","        train_accuracy = correct_train / total_train\n","        val_accuracy = validate(test_loader, model, device)\n","\n","        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","        scheduler.step(val_accuracy)\n","\n","        # Save checkpoint periodically\n","        if epoch % 5 == 0:  # For example, every 5 epochs\n","            save_checkpoint(model, optimizer, epoch, avg_loss)\n","\n","        if val_accuracy > best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        if epochs_without_improvement >= max_epochs_without_improvement:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","    model.eval()\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for batch in test_loader:\n","        batch = batch.to(device)\n","        with torch.no_grad():\n","            pred = model(batch).max(dim=1)[1]\n","            all_preds.extend(pred.cpu().numpy())\n","            all_labels.extend(batch.y.cpu().numpy())\n","            correct += pred.eq(batch.y).sum().item()\n","\n","    accuracy = correct / len(test_dataset)\n","    print(f\"Accuracy: {accuracy}\")\n","    print(\"Sample predictions:\", all_preds[:20])\n","    print(\"Sample true labels:\", all_labels[:20])\n","\n","    return model, all_preds, all_labels, accuracy"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"rr2PlwLy5M6H","executionInfo":{"status":"ok","timestamp":1702447468884,"user_tz":420,"elapsed":738742,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9cf586a-bfc0-462f-edb1-1051f484ed92"},"outputs":[{"output_type":"stream","name":"stderr","text":["Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Loaded sign 'dad' with 378 examples\n","Sign 'dad': Created 378 graphs\n","Loaded sign 'TV' with 385 examples\n","Sign 'TV': Created 385 graphs\n","Loaded sign 'flower' with 396 examples\n","Sign 'flower': Created 396 graphs\n","Loaded sign 'dance' with 312 examples\n","Sign 'dance': Created 312 graphs\n","Loaded sign 'cry' with 390 examples\n","Sign 'cry': Created 390 graphs\n","Loaded sign 'callonphone' with 385 examples\n","Sign 'callonphone': Created 385 graphs\n"]},{"output_type":"stream","name":"stderr","text":["Done!\n"]}],"source":["MAX_FILES = 6\n","directory_path = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/Datasets/processed-40-500-3\"\n","\n","# Create an instance of the ASLInMemoryDataset\n","dataset = ASLInMemoryDataset(root=directory_path)\n","# Accessing sign_to_label and num_classes\n","sign_to_label_map = dataset.sign_to_label_map\n","total_num_classes = dataset.total_num_classes"]},{"cell_type":"code","source":["# Split the dataset into training and validation subsets\n","train_data, val_data = stratified_data_split(dataset)"],"metadata":{"id":"LULs-iE5bIkS","executionInfo":{"status":"ok","timestamp":1702447469248,"user_tz":420,"elapsed":371,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Train the model using the datasets\n","model, all_preds, all_labels, accuracy = train(train_data, val_data, num_classes=total_num_classes, EPOCHS=100, LEARNING_RATE=0.001)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRr9tpynbPHB","outputId":"94d3dd6f-7389-4c73-b014-e341588f6174","executionInfo":{"status":"ok","timestamp":1702460548836,"user_tz":420,"elapsed":13079590,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Training label distribution: Counter({2: 317, 4: 312, 1: 308, 5: 308, 0: 302, 3: 249})\n","Test label distribution: Counter({2: 79, 4: 78, 1: 77, 5: 77, 0: 76, 3: 63})\n","Epoch 0, Loss: 1.1038, Training Accuracy: 0.1765, Validation Accuracy: 0.1689\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-061030-epoch-0.pth\n","Epoch 1, Loss: 1.8592, Training Accuracy: 0.1782, Validation Accuracy: 0.2311\n","Epoch 2, Loss: 1.8631, Training Accuracy: 0.1943, Validation Accuracy: 0.2044\n","Epoch 3, Loss: 1.7237, Training Accuracy: 0.2884, Validation Accuracy: 0.2800\n","Epoch 4, Loss: 1.4528, Training Accuracy: 0.4432, Validation Accuracy: 0.5067\n","Epoch 5, Loss: 1.2602, Training Accuracy: 0.5184, Validation Accuracy: 0.5044\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-063816-epoch-5.pth\n","Epoch 6, Loss: 1.1263, Training Accuracy: 0.5768, Validation Accuracy: 0.5600\n","Epoch 7, Loss: 0.9993, Training Accuracy: 0.6375, Validation Accuracy: 0.5956\n","Epoch 8, Loss: 0.9300, Training Accuracy: 0.6732, Validation Accuracy: 0.6178\n","Epoch 9, Loss: 0.8182, Training Accuracy: 0.7066, Validation Accuracy: 0.6800\n","Epoch 10, Loss: 0.3989, Training Accuracy: 0.7249, Validation Accuracy: 0.6756\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-070603-epoch-10.pth\n","Validation Accuracy after 60 batches: 0.6667\n","Epoch 11, Loss: 0.7954, Training Accuracy: 0.7316, Validation Accuracy: 0.6289\n","Validation Accuracy after 60 batches: 0.6000\n","Epoch 12, Loss: 0.7531, Training Accuracy: 0.7416, Validation Accuracy: 0.7222\n","Validation Accuracy after 60 batches: 0.7178\n","Epoch 13, Loss: 0.6730, Training Accuracy: 0.7745, Validation Accuracy: 0.6911\n","Validation Accuracy after 60 batches: 0.7000\n","Epoch 14, Loss: 0.6036, Training Accuracy: 0.7951, Validation Accuracy: 0.6978\n","Validation Accuracy after 60 batches: 0.7467\n","Epoch 15, Loss: 0.5840, Training Accuracy: 0.8213, Validation Accuracy: 0.7067\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-073722-epoch-15.pth\n","Validation Accuracy after 60 batches: 0.7578\n","Epoch 16, Loss: 0.5261, Training Accuracy: 0.8357, Validation Accuracy: 0.7244\n","Validation Accuracy after 60 batches: 0.7689\n","Epoch 17, Loss: 0.5018, Training Accuracy: 0.8391, Validation Accuracy: 0.7111\n","Validation Accuracy after 60 batches: 0.7778\n","Epoch 18, Loss: 0.4905, Training Accuracy: 0.8324, Validation Accuracy: 0.7400\n","Validation Accuracy after 60 batches: 0.7911\n","Epoch 19, Loss: 0.4255, Training Accuracy: 0.8686, Validation Accuracy: 0.7511\n","Validation Accuracy after 60 batches: 0.7578\n","Epoch 20, Loss: 0.4447, Training Accuracy: 0.8619, Validation Accuracy: 0.7244\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-080836-epoch-20.pth\n","Validation Accuracy after 60 batches: 0.7778\n","Epoch 21, Loss: 0.4059, Training Accuracy: 0.8686, Validation Accuracy: 0.7822\n","Validation Accuracy after 60 batches: 0.7600\n","Epoch 22, Loss: 0.3835, Training Accuracy: 0.8753, Validation Accuracy: 0.8022\n","Validation Accuracy after 60 batches: 0.7689\n","Epoch 23, Loss: 0.3575, Training Accuracy: 0.8953, Validation Accuracy: 0.7867\n","Validation Accuracy after 60 batches: 0.8111\n","Epoch 24, Loss: 0.3120, Training Accuracy: 0.9092, Validation Accuracy: 0.7622\n","Validation Accuracy after 60 batches: 0.7667\n","Epoch 25, Loss: 0.3102, Training Accuracy: 0.9098, Validation Accuracy: 0.7844\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-083945-epoch-25.pth\n","Validation Accuracy after 60 batches: 0.7822\n","Epoch 26, Loss: 0.2819, Training Accuracy: 0.9209, Validation Accuracy: 0.7911\n","Validation Accuracy after 60 batches: 0.7911\n","Epoch 27, Loss: 0.2562, Training Accuracy: 0.9237, Validation Accuracy: 0.8089\n","Validation Accuracy after 60 batches: 0.7956\n","Epoch 28, Loss: 0.2573, Training Accuracy: 0.9232, Validation Accuracy: 0.7933\n","Validation Accuracy after 60 batches: 0.7822\n","Epoch 29, Loss: 0.2322, Training Accuracy: 0.9349, Validation Accuracy: 0.8067\n","Validation Accuracy after 60 batches: 0.8022\n","Epoch 30, Loss: 0.2100, Training Accuracy: 0.9393, Validation Accuracy: 0.8200\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-091050-epoch-30.pth\n","Validation Accuracy after 60 batches: 0.8267\n","Epoch 31, Loss: 0.2307, Training Accuracy: 0.9365, Validation Accuracy: 0.7533\n","Validation Accuracy after 60 batches: 0.8111\n","Epoch 32, Loss: 0.2287, Training Accuracy: 0.9360, Validation Accuracy: 0.8156\n","Validation Accuracy after 60 batches: 0.8111\n","Epoch 33, Loss: 0.1944, Training Accuracy: 0.9415, Validation Accuracy: 0.7978\n","Validation Accuracy after 60 batches: 0.7978\n","Epoch 34, Loss: 0.1998, Training Accuracy: 0.9454, Validation Accuracy: 0.7933\n","Validation Accuracy after 60 batches: 0.8000\n","Epoch 35, Loss: 0.1905, Training Accuracy: 0.9493, Validation Accuracy: 0.7511\n","Checkpoint saved: /content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/ModelCheckpoints/checkpoint-20231213-094158-epoch-35.pth\n","Early stopping triggered.\n","Accuracy: 0.7511111111111111\n","Sample predictions: [3, 1, 5, 0, 4, 4, 4, 2, 4, 0, 3, 3, 1, 0, 2, 1, 4, 4, 5, 3]\n","Sample true labels: [3, 1, 4, 0, 4, 4, 4, 2, 4, 1, 3, 1, 1, 0, 2, 1, 4, 4, 3, 3]\n"]}]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F3mw0GID92WF","executionInfo":{"status":"ok","timestamp":1702484386770,"user_tz":420,"elapsed":157,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"64df8886-d43f-48b2-d2fe-3743d2fa393a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["ASLGraphClassifier(\n","  (conv1): GCNConv(6, 512)\n","  (bn1): BatchNorm(512)\n","  (conv2): GCNConv(512, 1024)\n","  (bn2): BatchNorm(1024)\n","  (ln1): LayerNorm(1024, affine=True, mode=graph)\n","  (lin1): Linear(in_features=1024, out_features=512, bias=True)\n","  (ln2): LayerNorm(512, affine=True, mode=graph)\n","  (lin2): Linear(in_features=512, out_features=6, bias=True)\n","  (dropout): Dropout(p=0.7, inplace=False)\n",")\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/SavedModels/Best-GNN-5-Weights.pth')"],"metadata":{"id":"I9aZrYomnTuq","executionInfo":{"status":"ok","timestamp":1702460548837,"user_tz":420,"elapsed":18,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"sMrYkTs89Q7O","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1702460549666,"user_tz":420,"elapsed":831,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"02768a03-2866-4af6-d729-6dcfecea6b17"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy for class 0 (dad): 93.42%\n","Accuracy for class 1 (TV): 57.14%\n","Accuracy for class 2 (flower): 68.35%\n","Accuracy for class 3 (dance): 71.43%\n","Accuracy for class 4 (cry): 76.92%\n","Accuracy for class 5 (callonphone): 83.12%\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         dad       0.78      0.93      0.85        76\n","          TV       0.81      0.57      0.67        77\n","      flower       0.93      0.68      0.79        79\n","       dance       0.63      0.71      0.67        63\n","         cry       0.79      0.77      0.78        78\n"," callonphone       0.64      0.83      0.72        77\n","\n","    accuracy                           0.75       450\n","   macro avg       0.76      0.75      0.75       450\n","weighted avg       0.77      0.75      0.75       450\n","\n"]}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# Convert lists to numpy arrays for compatibility with sklearn\n","y_true = np.array(all_labels)\n","y_pred = np.array(all_preds)\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","\n","# Visualize the confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.show()\n","\n","# Ensure the class names are in the correct order for target_names\n","ordered_class_names = [name for name, num in sorted(dataset.sign_to_label().items(), key=lambda item: item[1])]\n","\n","# Per-Class Accuracy\n","class_accuracy = cm.diagonal() / cm.sum(axis=1)\n","for i, acc in enumerate(class_accuracy):\n","    class_name = ordered_class_names[i]\n","    print(f\"Accuracy for class {i} ({class_name}): {acc*100:.2f}%\")\n","\n","# Detailed classification report\n","print(\"\\nClassification Report:\\n\")\n","print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=1))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Hl5tQmtN9Syt","executionInfo":{"status":"ok","timestamp":1702460549666,"user_tz":420,"elapsed":5,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def print_top_misclassified_classes(y_true, y_pred, sign_to_label, N=3, zero_division=1):\n","    \"\"\"\n","    Prints the top N classes that get misclassified the most.\n","\n","    Parameters:\n","    - y_true: Actual labels\n","    - y_pred: Predicted labels by the model\n","    - sign_to_label: Dictionary mapping class names to class numbers\n","    - N: Number of top misclassified classes to print\n","    - zero_division: Parameter for handling zero division in classification_report\n","\n","    Returns:\n","    None\n","    \"\"\"\n","\n","    # Ensure the class names are in the correct order for target_names\n","    ordered_class_names = [name for name, num in sorted(sign_to_label.items(), key=lambda item: item[1])]\n","\n","    # Generate and print classification report with class names\n","    print(\"\\nClassification Report:\\n\")\n","    print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=zero_division))\n","\n","    # Generate classification report as dict to find misclassified classes\n","    report = classification_report(y_true, y_pred, output_dict=True, zero_division=zero_division)\n","\n","    # Create a dictionary to store misclassification rates\n","    misclassification_rates = {}\n","\n","    # Iterate through each class in the report\n","    for class_num, metrics in report.items():\n","        if class_num.isdigit():\n","            class_name = [key for key, value in sign_to_label.items() if value == int(class_num)][0]\n","            misclassification_rates[class_name] = 1 - metrics['recall']\n","\n","    # Sort classes based on misclassification rate\n","    sorted_classes = sorted(misclassification_rates, key=misclassification_rates.get, reverse=True)\n","\n","    # Print top N misclassified classes\n","    print(f\"\\nTop {N} misclassified classes:\")\n","    for i in range(N):\n","        class_name = sorted_classes[i]\n","        print(f\"{i+1}. {class_name} - Misclassification rate: {misclassification_rates[class_name]:.2f}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"m4ZtqFxz9XlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702460549666,"user_tz":420,"elapsed":5,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"48651712-e66a-4b40-d4ae-bc99a3924ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","         dad       0.78      0.93      0.85        76\n","          TV       0.81      0.57      0.67        77\n","      flower       0.93      0.68      0.79        79\n","       dance       0.63      0.71      0.67        63\n","         cry       0.79      0.77      0.78        78\n"," callonphone       0.64      0.83      0.72        77\n","\n","    accuracy                           0.75       450\n","   macro avg       0.76      0.75      0.75       450\n","weighted avg       0.77      0.75      0.75       450\n","\n","\n","Top 6 misclassified classes:\n","1. TV - Misclassification rate: 0.43\n","2. flower - Misclassification rate: 0.32\n","3. dance - Misclassification rate: 0.29\n","4. cry - Misclassification rate: 0.23\n","5. callonphone - Misclassification rate: 0.17\n","6. dad - Misclassification rate: 0.07\n"]}],"source":["N = 10 if MAX_FILES > 50 else MAX_FILES\n","print_top_misclassified_classes(y_true, y_pred, sign_to_label_map, N=N, zero_division=1)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1wIPH3B0fuuoSlPfXK5fGd9Em1LP-uQFJ","timestamp":1697014386160}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}