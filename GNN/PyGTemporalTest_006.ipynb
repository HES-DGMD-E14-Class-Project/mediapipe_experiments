{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ewruGCyaCn",
        "outputId": "e4c43606-7ff9-4b11-b65d-2d2e1c48405c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiSS4wuxZ01m",
        "outputId": "5bcb9e9d-bc59-4f22-edbc-14b15123b68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cu118\n",
            "11.8\n",
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m956.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.0.1+cu118)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.2)\n",
            "Collecting pandas<=1.3.5 (from torch-geometric-temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse (from torch-geometric-temporal)\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_scatter (from torch-geometric-temporal)\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_geometric (from torch-geometric-temporal)\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-geometric-temporal) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-geometric-temporal) (17.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-geometric-temporal) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal, torch_geometric, torch_scatter, torch_sparse\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=297c77fe0eb7c127b607a383668afbd711685dd54a4f6eb496f68cb513f1220a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=756438c9880531969152ff5777c1a23b9a60272ea4cc9d327e116f0bbf7768a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=494366 sha256=b756f78f0f1e4fdd485e510e117232f82aa811b420bf8f4b30167a6ecc296a28\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1054272 sha256=bb26e5dc7d092a03c61a25e107e07ab94e694e8c517dffd0cbffc4c4654086b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "Successfully built torch-geometric-temporal torch_geometric torch_scatter torch_sparse\n",
            "Installing collected packages: torch_scatter, torch_sparse, pandas, torch_geometric, torch-geometric-temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.3 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5 torch-geometric-temporal-0.54.0 torch_geometric-2.3.1 torch_scatter-2.1.2 torch_sparse-0.6.18\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "\n",
        "!pip install torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi7c7EMpsCBX"
      },
      "source": [
        "### `ASLDatasetLoader` Class\n",
        "\n",
        "The `ASLDatasetLoader` class is designed for loading and processing the ASL dataset. Given a directory, it reads sign language data from JSON files and constructs graph representations suitable for graph-based neural networks. Crucially, the class converts JSON data into PyTorch Geometric (PyG) `Data` objects comprising `x` (node features), `edge_index` (graph connectivity), and `y' (labels) attributes.\n",
        "\n",
        "**Methods**:\n",
        "\n",
        "- `_create_sign_to_label_map`: Generates a mapping from sign names to unique labels.\n",
        "\n",
        "- `_read_file_data`: Reads data from a given JSON file.\n",
        "\n",
        "- `_augment_data`: Implements data augmentation by applying random rotation, translation, and scaling to landmarks, which can enhance the model's robustness.\n",
        "\n",
        "- `_create_graph_from_frame`: Constructs a PyG `Data` object from frame data, concentrating on hand and face landmarks. Edges are created between consecutive landmarks and between left and right hand landmarks. Additional features, like hand-to-face distances, are also computed.\n",
        "\n",
        "- `get_dataset`: Assembles the dataset, optionally incorporating data augmentation. The function outputs a list of PyG `Data` objects ready for graph neural network processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LifBvD3D4t4C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "HAND_TO_FACE_THRESHOLD = 0.05\n",
        "\n",
        "class ASLDatasetLoader:\n",
        "    def __init__(self, directory_path):\n",
        "        self.directory_path = directory_path\n",
        "        self.sign_to_label = self._create_sign_to_label_map()\n",
        "\n",
        "    def _create_sign_to_label_map(self):\n",
        "        signs = [os.path.splitext(filename)[0] for filename in os.listdir(self.directory_path)]\n",
        "        return {sign: i for i, sign in enumerate(signs)}\n",
        "\n",
        "    def _read_file_data(self, file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1):\n",
        "        \"\"\"\n",
        "        Augment the frame data with random rotation, translation, and scaling.\n",
        "\n",
        "        :param frame_data: Dictionary containing frame landmarks and deltas.\n",
        "        :param rotation_range: Maximum rotation angle in degrees.\n",
        "        :param translation_range: Maximum translation as a fraction of landmark range.\n",
        "        :param scaling_range: Maximum scaling factor.\n",
        "        :return: Augmented frame data.\n",
        "        \"\"\"\n",
        "        landmarks = np.array(frame_data[\"landmarks\"])\n",
        "        centroid = np.mean(landmarks, axis=0)\n",
        "\n",
        "        # Random rotation\n",
        "        theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(theta), -np.sin(theta)],\n",
        "            [np.sin(theta), np.cos(theta)]\n",
        "        ])\n",
        "        landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n",
        "\n",
        "        # Random translation\n",
        "        max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n",
        "        translations = np.random.uniform(-max_translation, max_translation)\n",
        "        landmarks += translations\n",
        "\n",
        "        # Random scaling\n",
        "        scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n",
        "        landmarks = centroid + scale * (landmarks - centroid)\n",
        "\n",
        "        frame_data[\"landmarks\"] = landmarks.tolist()\n",
        "        return frame_data\n",
        "\n",
        "    def _create_graph_from_frame(self, sign_name, frame_data, landmark_types):\n",
        "        left_hand_indices = [i for i, t in enumerate(landmark_types) if t == \"L\"]\n",
        "        right_hand_indices = [i for i, t in enumerate(landmark_types) if t == \"R\"]\n",
        "        face_indices = [i for i, t in enumerate(landmark_types) if t == \"F\"]\n",
        "\n",
        "        landmarks = np.array(frame_data[\"landmarks\"])\n",
        "        deltas = np.array(frame_data[\"deltas\"])\n",
        "\n",
        "        # Create weights based on landmark importance\n",
        "        weights = [2 if t == \"L\" or t == \"R\" else 1 for t in landmark_types]\n",
        "\n",
        "        # Create edges based on the number of available landmarks (or nodes)\n",
        "        edges = [[i, i + 1] for i in range(len(landmarks) - 1)]\n",
        "\n",
        "        # Add edges between the left and right hand landmarks\n",
        "        for i in left_hand_indices:\n",
        "            for j in right_hand_indices:\n",
        "                edges.append([i, j])\n",
        "\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "        # Compute additional features like hand-to-face and hand-to-body distances\n",
        "        hand_to_face_contact = []\n",
        "        for idx, ltype in enumerate(landmark_types):\n",
        "            if ltype in [\"L\", \"R\"] and any(t == \"F\" for t in landmark_types):\n",
        "                min_distance = min([np.linalg.norm(landmarks[idx] - landmarks[j]) for j, t in enumerate(landmark_types) if t == \"F\"])\n",
        "                hand_to_face_contact.append(1 if min_distance < HAND_TO_FACE_THRESHOLD else 0)\n",
        "            else:\n",
        "                hand_to_face_contact.append(0)\n",
        "\n",
        "        # Reshape the 1D arrays to 2D for concatenation\n",
        "        weights_2d = np.array(weights)[:, np.newaxis]\n",
        "        hand_to_face_contact_2d = np.array(hand_to_face_contact)[:, np.newaxis]\n",
        "\n",
        "        # Concatenate landmarks, deltas, importance weights, and hand-to-face contact features\n",
        "        x = torch.tensor(np.hstack((landmarks, deltas, weights_2d, hand_to_face_contact_2d)), dtype=torch.float)\n",
        "        y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "\n",
        "    def get_dataset(self, augment=False):\n",
        "        dataset = []\n",
        "\n",
        "        for filename in os.listdir(self.directory_path):\n",
        "            sign_name = os.path.splitext(filename)[0]\n",
        "            file_path = os.path.join(self.directory_path, filename)\n",
        "            sign_data = self._read_file_data(file_path)\n",
        "\n",
        "            for frame_data in sign_data[\"frames\"]:\n",
        "                landmark_types = sign_data.get(\"landmark_types\", [\"F\", \"L\", \"P\", \"R\"])  # defaulting to all types\n",
        "\n",
        "                if augment:\n",
        "                  frame_data = self._augment_data(frame_data)\n",
        "                graph_data = self._create_graph_from_frame(sign_name, frame_data, landmark_types)\n",
        "\n",
        "                dataset.append(graph_data)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def number_of_classes(self):\n",
        "        return len(self.sign_to_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xooW2sogtdL1"
      },
      "source": [
        "### `ASLGraphClassifier` Class\n",
        "\n",
        "The `ASLGraphClassifier` is a Graph Convolutional Network (GCN) classifier that handles graph-structured data. It accepts a PyG `Data` object as input and produces class logits via the forward pass, which, when paired with a suitable loss function, aids in model training.\n",
        "\n",
        "**Methods**:\n",
        "\n",
        "- `forward`: Defines the forward pass of the model. Accepting a PyG `Data` object containing the entire graph, the method comprises two GCN layers with subsequent batch normalization and dropout layers process the input. Post global max-pooling, two linear layers coupled with dropout ensure final classification, leading to log-softmax outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RAslUK79VVV6"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_max_pool, global_mean_pool\n",
        "\n",
        "class ASLGraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        super(ASLGraphClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 256)  # Increased channels\n",
        "        self.bn1 = torch.nn.BatchNorm1d(256)    # Batch normalization layer\n",
        "        self.conv2 = GCNConv(256, 512)          # Increased channels\n",
        "        self.bn2 = torch.nn.BatchNorm1d(512)    # Batch normalization layer\n",
        "        self.lin1 = torch.nn.Linear(512, 256)\n",
        "        self.lin2 = torch.nn.Linear(256, num_classes)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
        "        x = self.dropout(x)\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RdBGsFveWcbF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric.loader import DataLoader\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "EPOCHS = 200\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "\n",
        "def stratified_data_split(data_list, test_size=0.2):\n",
        "    \"\"\"\n",
        "    This function splits a dataset into training and testing subsets, preserving\n",
        "    the class distribution by leveraging the stratification capabilities of\n",
        "    `train_test_split` from `sklearn`. Stratification helps with potential class\n",
        "    imbalances.\n",
        "    \"\"\"\n",
        "    # Extract labels from data list\n",
        "    labels = [data.y.item() for data in data_list]\n",
        "\n",
        "    # Use sklearn's train_test_split with stratify option\n",
        "    train_data, test_data = train_test_split(data_list, test_size=test_size, stratify=labels, random_state=42)\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "def validate(loader, model, device):\n",
        "    \"\"\"\n",
        "    Used to evaluate the model on validation/test data, computing accuracy as a\n",
        "    performance metric, and offering insights into the model's efficacy.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def train():\n",
        "    \"\"\"\n",
        "    The `train` function establishes the training loop for the graph-based\n",
        "    neural network. It enacts typical training loop tasks like logging\n",
        "    epoch-wise loss, validation, and early stopping.\n",
        "\n",
        "    The function also harnesses schedulers, regularization techniques, and\n",
        "    gradient clipping to ensure smooth and optimal training.\n",
        "    \"\"\"\n",
        "    directory_path = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/Datasets/ASL\"\n",
        "    loader = ASLDatasetLoader(directory_path)\n",
        "\n",
        "    # Create the entire dataset without augmentation and then perform stratified split\n",
        "    data_list = loader.get_dataset()\n",
        "    train_dataset, test_dataset = stratified_data_split(data_list, test_size=0.2)\n",
        "\n",
        "    # Now augment only the training dataset\n",
        "    augmented_train_dataset = loader.get_dataset(augment=True)\n",
        "\n",
        "    num_classes = loader.number_of_classes()\n",
        "\n",
        "    train_labels = [data.y.item() for data in train_dataset]\n",
        "    test_labels = [data.y.item() for data in test_dataset]\n",
        "\n",
        "    print(\"Training label distribution:\", Counter(train_labels))\n",
        "    print(\"Test label distribution:\", Counter(test_labels))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    num_features = train_dataset[0].x.size(1)\n",
        "    model = ASLGraphClassifier(num_features=num_features, num_classes=num_classes).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=5, verbose=True)\n",
        "\n",
        "    max_epochs_without_improvement = 20\n",
        "    epochs_without_improvement = 0\n",
        "    best_val_accuracy = 0\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = F.nll_loss(out, batch.y)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if np.isnan(loss.item()):\n",
        "                print(\"Warning: NaN loss detected!\")\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n",
        "\n",
        "        val_accuracy = validate(test_loader, model, device)\n",
        "        scheduler.step(val_accuracy)\n",
        "\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= max_epochs_without_improvement:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch).max(dim=1)[1]\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(batch.y.cpu().numpy())\n",
        "            correct += pred.eq(batch.y).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {correct / len(test_dataset)}\")\n",
        "    print(\"Sample predictions:\", all_preds[:20])\n",
        "    print(\"Sample true labels:\", all_labels[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr2PlwLy5M6H",
        "outputId": "3e8db206-f27e-4db2-a2e5-8ece7fe6070f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training label distribution: Counter({0: 438, 2: 430, 131: 430, 3: 420, 125: 402, 1: 400, 116: 363, 128: 346, 130: 338, 126: 338, 104: 332, 127: 330, 85: 324, 101: 323, 103: 316, 113: 310, 98: 309, 84: 308, 96: 307, 102: 306, 129: 304, 121: 298, 97: 297, 86: 297, 87: 296, 100: 295, 83: 295, 95: 295, 99: 294, 88: 293, 64: 292, 89: 290, 90: 289, 94: 288, 66: 286, 119: 282, 77: 279, 91: 279, 76: 278, 63: 278, 93: 278, 73: 277, 50: 277, 80: 276, 92: 275, 72: 274, 78: 274, 68: 274, 52: 273, 55: 273, 79: 271, 74: 270, 70: 270, 53: 270, 71: 270, 120: 269, 56: 269, 67: 268, 75: 266, 82: 265, 117: 265, 62: 265, 45: 264, 57: 263, 81: 263, 48: 263, 60: 262, 69: 262, 35: 262, 65: 262, 61: 261, 54: 261, 59: 261, 40: 260, 123: 258, 41: 258, 38: 257, 49: 256, 32: 255, 34: 255, 24: 255, 30: 254, 44: 254, 58: 253, 51: 253, 46: 252, 28: 251, 26: 250, 43: 250, 47: 250, 25: 250, 29: 249, 37: 249, 14: 247, 17: 247, 42: 247, 15: 247, 114: 247, 39: 247, 23: 246, 122: 246, 20: 246, 31: 244, 19: 244, 226: 243, 118: 243, 227: 243, 115: 242, 18: 242, 36: 242, 16: 241, 10: 241, 5: 241, 223: 240, 13: 240, 27: 239, 9: 239, 33: 238, 22: 238, 8: 238, 221: 238, 7: 237, 220: 237, 208: 236, 124: 236, 11: 236, 207: 235, 4: 235, 205: 234, 12: 234, 206: 234, 211: 234, 203: 234, 215: 234, 218: 234, 21: 234, 217: 233, 6: 233, 222: 231, 224: 230, 194: 230, 216: 230, 209: 229, 214: 229, 198: 229, 212: 229, 219: 227, 225: 226, 213: 226, 200: 226, 202: 226, 210: 225, 185: 224, 197: 224, 199: 224, 105: 223, 201: 223, 204: 223, 189: 223, 184: 222, 174: 222, 186: 222, 188: 222, 195: 222, 193: 222, 192: 222, 172: 221, 107: 220, 167: 219, 191: 219, 196: 218, 178: 218, 176: 218, 181: 218, 190: 217, 187: 216, 179: 215, 112: 215, 157: 214, 108: 214, 180: 214, 175: 213, 177: 212, 173: 211, 171: 211, 182: 210, 106: 210, 169: 209, 161: 209, 160: 209, 164: 209, 159: 208, 162: 208, 183: 208, 170: 207, 156: 206, 168: 206, 158: 206, 165: 206, 163: 205, 142: 204, 166: 204, 154: 204, 152: 204, 109: 203, 155: 202, 144: 202, 150: 202, 146: 202, 151: 201, 153: 201, 111: 199, 143: 199, 110: 199, 139: 198, 149: 198, 147: 198, 140: 197, 141: 197, 148: 197, 145: 196, 137: 195, 136: 194, 135: 193, 134: 193, 133: 188, 132: 185, 138: 182})\n",
            "Test label distribution: Counter({0: 109, 2: 108, 131: 107, 3: 105, 125: 100, 1: 100, 116: 91, 128: 86, 130: 85, 126: 84, 104: 83, 127: 83, 101: 81, 85: 81, 103: 79, 113: 78, 84: 77, 102: 77, 98: 77, 96: 77, 129: 76, 121: 75, 83: 74, 97: 74, 99: 74, 87: 74, 86: 74, 100: 74, 95: 74, 64: 73, 89: 73, 88: 73, 90: 72, 94: 72, 66: 72, 77: 70, 119: 70, 63: 70, 91: 70, 93: 70, 50: 69, 73: 69, 80: 69, 92: 69, 76: 69, 68: 69, 79: 68, 52: 68, 72: 68, 55: 68, 78: 68, 74: 68, 53: 67, 71: 67, 70: 67, 75: 67, 120: 67, 67: 67, 56: 67, 69: 66, 65: 66, 45: 66, 82: 66, 81: 66, 60: 66, 117: 66, 57: 66, 62: 66, 48: 66, 54: 65, 61: 65, 59: 65, 40: 65, 35: 65, 123: 65, 32: 64, 38: 64, 34: 64, 24: 64, 49: 64, 41: 64, 30: 64, 44: 63, 28: 63, 58: 63, 51: 63, 26: 63, 25: 63, 43: 63, 46: 63, 23: 62, 37: 62, 122: 62, 17: 62, 15: 62, 114: 62, 42: 62, 39: 62, 29: 62, 14: 62, 47: 62, 20: 62, 18: 61, 115: 61, 118: 61, 36: 61, 19: 61, 227: 61, 226: 61, 31: 61, 27: 60, 10: 60, 22: 60, 13: 60, 223: 60, 9: 60, 16: 60, 5: 60, 33: 59, 206: 59, 21: 59, 4: 59, 208: 59, 221: 59, 207: 59, 215: 59, 11: 59, 7: 59, 218: 59, 124: 59, 8: 59, 220: 59, 12: 58, 222: 58, 203: 58, 217: 58, 211: 58, 205: 58, 6: 58, 216: 57, 219: 57, 209: 57, 198: 57, 225: 57, 194: 57, 212: 57, 214: 57, 224: 57, 200: 56, 201: 56, 189: 56, 202: 56, 185: 56, 199: 56, 197: 56, 210: 56, 184: 56, 213: 56, 186: 56, 174: 56, 105: 56, 204: 56, 195: 56, 172: 55, 191: 55, 188: 55, 193: 55, 176: 55, 107: 55, 192: 55, 167: 55, 196: 55, 187: 54, 190: 54, 179: 54, 112: 54, 181: 54, 180: 54, 178: 54, 157: 53, 171: 53, 108: 53, 175: 53, 182: 53, 177: 53, 173: 53, 162: 52, 160: 52, 158: 52, 183: 52, 159: 52, 161: 52, 106: 52, 170: 52, 169: 52, 164: 52, 165: 51, 156: 51, 150: 51, 166: 51, 146: 51, 142: 51, 168: 51, 163: 51, 154: 51, 152: 51, 155: 51, 109: 51, 139: 50, 144: 50, 110: 50, 143: 50, 151: 50, 153: 50, 111: 50, 147: 49, 141: 49, 136: 49, 149: 49, 148: 49, 140: 49, 145: 49, 134: 48, 137: 48, 135: 48, 133: 47, 132: 46, 138: 45})\n",
            "Epoch 0, Loss: 4.996777091034383\n",
            "Epoch 1, Loss: 3.884266039666855\n",
            "Epoch 2, Loss: 3.5092436392249393\n",
            "Epoch 3, Loss: 3.3020632361234883\n",
            "Epoch 4, Loss: 3.1688425197633627\n",
            "Epoch 5, Loss: 3.0854761522412635\n",
            "Epoch 6, Loss: 3.0165106731912363\n",
            "Epoch 7, Loss: 2.9753640293065335\n",
            "Epoch 8, Loss: 2.9086571551527025\n",
            "Epoch 9, Loss: 2.8439077879331127\n",
            "Epoch 10, Loss: 2.799862600328692\n",
            "Epoch 11, Loss: 2.746617682770374\n",
            "Epoch 12, Loss: 2.7058325497731186\n",
            "Epoch 13, Loss: 2.6657857747484504\n",
            "Epoch 14, Loss: 2.6302759973831864\n",
            "Epoch 15, Loss: 2.5903178480370177\n",
            "Epoch 16, Loss: 2.554590203679934\n",
            "Epoch 17, Loss: 2.5361639220858616\n",
            "Epoch 18, Loss: 2.516810207364251\n",
            "Epoch 19, Loss: 2.4918942015296253\n",
            "Epoch 20, Loss: 2.4737330327122846\n",
            "Epoch 21, Loss: 2.4572549614106647\n",
            "Epoch 22, Loss: 2.4466294636502903\n",
            "Epoch 23, Loss: 2.4352642069557575\n",
            "Epoch 24, Loss: 2.4228810951037976\n",
            "Epoch 25, Loss: 2.4030034348898726\n",
            "Epoch 26, Loss: 2.385988417013697\n",
            "Epoch 27, Loss: 2.3801320416990612\n",
            "Epoch 28, Loss: 2.3625921449171225\n",
            "Epoch 29, Loss: 2.3522050964300543\n",
            "Epoch 30, Loss: 2.3464454407075377\n",
            "Epoch 31, Loss: 2.3325152232914843\n",
            "Epoch 32, Loss: 2.328887307192901\n",
            "Epoch 33, Loss: 2.326948858465198\n",
            "Epoch 34, Loss: 2.3040676663515596\n",
            "Epoch 35, Loss: 2.298796660478744\n",
            "Epoch 36, Loss: 2.291220287291227\n",
            "Epoch 37, Loss: 2.2758983365564545\n",
            "Epoch 38, Loss: 2.2738802469362316\n",
            "Epoch 00039: reducing learning rate of group 0 to 7.0000e-04.\n",
            "Epoch 39, Loss: 2.1854704040245174\n",
            "Epoch 40, Loss: 2.1566043164621025\n",
            "Epoch 41, Loss: 2.152049112562269\n",
            "Epoch 42, Loss: 2.140503549696967\n",
            "Epoch 43, Loss: 2.131127554706636\n",
            "Epoch 44, Loss: 2.1199178239977474\n",
            "Epoch 45, Loss: 2.118823662778875\n",
            "Epoch 46, Loss: 2.1088820586831876\n",
            "Epoch 47, Loss: 2.0989290440170056\n",
            "Epoch 48, Loss: 2.0944259700500516\n",
            "Epoch 49, Loss: 2.0853881896518165\n",
            "Epoch 50, Loss: 2.0757334217521715\n",
            "Epoch 51, Loss: 2.0700891005797684\n",
            "Epoch 52, Loss: 2.0598470533991318\n",
            "Epoch 53, Loss: 2.0503497290651653\n",
            "Epoch 54, Loss: 2.0418243777072074\n",
            "Epoch 55, Loss: 2.0342597854399935\n",
            "Epoch 56, Loss: 2.016392633377799\n",
            "Epoch 57, Loss: 2.010462083364193\n",
            "Epoch 58, Loss: 1.9914725762447485\n",
            "Epoch 59, Loss: 1.9839300309649166\n",
            "Epoch 60, Loss: 1.9688588617751317\n",
            "Epoch 61, Loss: 1.9605800771969042\n",
            "Epoch 62, Loss: 1.9432979786483533\n",
            "Epoch 63, Loss: 1.926460663589766\n",
            "Epoch 64, Loss: 1.9199490868930826\n",
            "Epoch 65, Loss: 1.9083759518143553\n",
            "Epoch 66, Loss: 1.8897995124894438\n",
            "Epoch 67, Loss: 1.876600866261207\n",
            "Epoch 68, Loss: 1.863248515371412\n",
            "Epoch 69, Loss: 1.8587679037059652\n",
            "Epoch 70, Loss: 1.8393345381633364\n",
            "Epoch 71, Loss: 1.8336132765489404\n",
            "Epoch 72, Loss: 1.8196417299251244\n",
            "Epoch 73, Loss: 1.8149484653448669\n",
            "Epoch 74, Loss: 1.79733094911263\n",
            "Epoch 75, Loss: 1.7986851629397749\n",
            "Epoch 76, Loss: 1.7962728105380263\n",
            "Epoch 00077: reducing learning rate of group 0 to 4.9000e-04.\n",
            "Epoch 77, Loss: 1.7143421211800018\n",
            "Epoch 78, Loss: 1.6965492098833599\n",
            "Epoch 79, Loss: 1.6852988307251222\n",
            "Epoch 80, Loss: 1.6823566316346674\n",
            "Epoch 81, Loss: 1.6697115283238557\n",
            "Epoch 82, Loss: 1.6584430093619864\n",
            "Epoch 83, Loss: 1.6545750359772693\n",
            "Epoch 84, Loss: 1.6539689652129528\n",
            "Epoch 85, Loss: 1.6496411433063747\n",
            "Epoch 86, Loss: 1.645056690892414\n",
            "Epoch 87, Loss: 1.6402486362476123\n",
            "Epoch 88, Loss: 1.6359407081905561\n",
            "Epoch 89, Loss: 1.6328657302797212\n",
            "Epoch 00090: reducing learning rate of group 0 to 3.4300e-04.\n",
            "Epoch 90, Loss: 1.5761511860292285\n",
            "Epoch 91, Loss: 1.561705104413509\n",
            "Epoch 92, Loss: 1.5570228400370416\n",
            "Epoch 93, Loss: 1.5491302364765083\n",
            "Epoch 94, Loss: 1.5480462657671605\n",
            "Epoch 95, Loss: 1.5420136678562133\n",
            "Epoch 96, Loss: 1.5368248808525296\n",
            "Epoch 97, Loss: 1.5369312830525963\n",
            "Epoch 98, Loss: 1.5361051500213811\n",
            "Epoch 99, Loss: 1.5320442442770128\n",
            "Epoch 100, Loss: 1.5292268370181945\n",
            "Epoch 101, Loss: 1.5293440148360578\n",
            "Epoch 102, Loss: 1.5270343046953017\n",
            "Epoch 103, Loss: 1.5256646217295573\n",
            "Epoch 104, Loss: 1.5247549942696181\n",
            "Epoch 105, Loss: 1.5202648334756266\n",
            "Epoch 106, Loss: 1.519251663997172\n",
            "Epoch 00107: reducing learning rate of group 0 to 2.4010e-04.\n",
            "Epoch 107, Loss: 1.4770740572508279\n",
            "Epoch 108, Loss: 1.4698342462840692\n",
            "Epoch 109, Loss: 1.4621871975705423\n",
            "Epoch 110, Loss: 1.460898448524335\n",
            "Epoch 111, Loss: 1.4574479812420673\n",
            "Epoch 112, Loss: 1.4526277895972664\n",
            "Epoch 113, Loss: 1.455482953184409\n",
            "Epoch 00114: reducing learning rate of group 0 to 1.6807e-04.\n",
            "Epoch 114, Loss: 1.4217126824167878\n",
            "Epoch 115, Loss: 1.4134805332059446\n",
            "Epoch 116, Loss: 1.4119975056640177\n",
            "Epoch 117, Loss: 1.4099866310665663\n",
            "Epoch 118, Loss: 1.4061248162787625\n",
            "Epoch 119, Loss: 1.4061755670927663\n",
            "Epoch 120, Loss: 1.3999545545244136\n",
            "Epoch 121, Loss: 1.3978522951356573\n",
            "Epoch 00122: reducing learning rate of group 0 to 1.1765e-04.\n",
            "Epoch 122, Loss: 1.3764087066079587\n",
            "Epoch 123, Loss: 1.3722821297381707\n",
            "Epoch 124, Loss: 1.3705109151186476\n",
            "Epoch 125, Loss: 1.3679210277077574\n",
            "Epoch 126, Loss: 1.36597404437574\n",
            "Epoch 127, Loss: 1.3647595564569208\n",
            "Epoch 128, Loss: 1.3647079319350803\n",
            "Epoch 129, Loss: 1.3641331552920672\n",
            "Epoch 130, Loss: 1.3608821591100473\n",
            "Epoch 131, Loss: 1.3588148547322787\n",
            "Epoch 132, Loss: 1.358019879549523\n",
            "Epoch 00133: reducing learning rate of group 0 to 8.2354e-05.\n",
            "Epoch 133, Loss: 1.3397484577893537\n",
            "Epoch 134, Loss: 1.337703176301324\n",
            "Epoch 135, Loss: 1.335464561308662\n",
            "Epoch 136, Loss: 1.3343992032687049\n",
            "Epoch 137, Loss: 1.332046737918606\n",
            "Epoch 138, Loss: 1.3308970751498528\n",
            "Epoch 139, Loss: 1.3295526462110134\n",
            "Epoch 140, Loss: 1.3290131097456481\n",
            "Epoch 141, Loss: 1.3277647617777346\n",
            "Epoch 00142: reducing learning rate of group 0 to 5.7648e-05.\n",
            "Epoch 142, Loss: 1.314888688297611\n",
            "Epoch 143, Loss: 1.3123074235181091\n",
            "Epoch 144, Loss: 1.3116832700642673\n",
            "Epoch 145, Loss: 1.3092176240423452\n",
            "Epoch 146, Loss: 1.3082063922028566\n",
            "Epoch 147, Loss: 1.307226103554332\n",
            "Epoch 148, Loss: 1.3044839971217645\n",
            "Epoch 149, Loss: 1.302847458069638\n",
            "Epoch 150, Loss: 1.3017290225478635\n",
            "Epoch 151, Loss: 1.3011938538139383\n",
            "Epoch 152, Loss: 1.2991501732373358\n",
            "Epoch 153, Loss: 1.2982580996986703\n",
            "Epoch 00154: reducing learning rate of group 0 to 4.0354e-05.\n",
            "Epoch 154, Loss: 1.2885654883355087\n",
            "Epoch 155, Loss: 1.2867949628547246\n",
            "Epoch 156, Loss: 1.2857961126938169\n",
            "Epoch 157, Loss: 1.2848418201853635\n",
            "Epoch 158, Loss: 1.2833250861999883\n",
            "Epoch 159, Loss: 1.2828883059209246\n",
            "Epoch 160, Loss: 1.2817253262763775\n",
            "Epoch 161, Loss: 1.2808953468103585\n",
            "Epoch 162, Loss: 1.2800547488324054\n",
            "Epoch 163, Loss: 1.2793079763398474\n",
            "Epoch 164, Loss: 1.2781599578650102\n",
            "Epoch 165, Loss: 1.278135708568461\n",
            "Epoch 166, Loss: 1.275912059120779\n",
            "Epoch 167, Loss: 1.2759879435071293\n",
            "Epoch 168, Loss: 1.2753966877111804\n",
            "Epoch 169, Loss: 1.2740518779555396\n",
            "Epoch 170, Loss: 1.2742158811621447\n",
            "Epoch 171, Loss: 1.2735525181507539\n",
            "Epoch 00172: reducing learning rate of group 0 to 2.8248e-05.\n",
            "Epoch 172, Loss: 1.266662839709669\n",
            "Epoch 173, Loss: 1.2655085353848625\n",
            "Epoch 174, Loss: 1.264815924195904\n",
            "Epoch 175, Loss: 1.2640515342396845\n",
            "Epoch 176, Loss: 1.2645433271826492\n",
            "Epoch 177, Loss: 1.263049864149713\n",
            "Epoch 178, Loss: 1.262705984895072\n",
            "Epoch 179, Loss: 1.2620052859515272\n",
            "Epoch 180, Loss: 1.2612025638814028\n",
            "Epoch 181, Loss: 1.2609526975083527\n",
            "Epoch 182, Loss: 1.2607344561280132\n",
            "Epoch 00183: reducing learning rate of group 0 to 1.9773e-05.\n",
            "Epoch 183, Loss: 1.255369489035453\n",
            "Epoch 184, Loss: 1.254869821379913\n",
            "Epoch 185, Loss: 1.2543318633101608\n",
            "Epoch 186, Loss: 1.2540061493366872\n",
            "Epoch 187, Loss: 1.254081275825242\n",
            "Epoch 188, Loss: 1.2535142541806756\n",
            "Epoch 189, Loss: 1.2528941737669865\n",
            "Epoch 00190: reducing learning rate of group 0 to 1.3841e-05.\n",
            "Epoch 190, Loss: 1.248856615811536\n",
            "Epoch 191, Loss: 1.2486178051408976\n",
            "Epoch 192, Loss: 1.2483547560445742\n",
            "Epoch 193, Loss: 1.2480441440908603\n",
            "Epoch 194, Loss: 1.248814119954758\n",
            "Epoch 195, Loss: 1.2478309610279046\n",
            "Epoch 196, Loss: 1.2483835604855869\n",
            "Epoch 197, Loss: 1.2474194080865968\n",
            "Epoch 198, Loss: 1.2467869564276641\n",
            "Epoch 199, Loss: 1.2472537629756464\n",
            "Accuracy: 0.7041587234343006\n",
            "Sample predictions: [217, 162, 54, 27, 125, 69, 126, 23, 66, 16, 139, 37, 54, 44, 64, 187, 109, 211, 33, 61]\n",
            "Sample true labels: [172, 162, 18, 27, 125, 69, 126, 23, 134, 133, 139, 37, 54, 44, 64, 187, 12, 191, 33, 61]\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
