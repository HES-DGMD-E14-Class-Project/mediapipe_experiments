{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiSS4wuxZ01m",
        "outputId": "140232bf-7969-4dcd-83f2-5df0d29e6d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "11.8\n",
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.0.1+cu118)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.2)\n",
            "Collecting pandas<=1.3.5 (from torch-geometric-temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse (from torch-geometric-temporal)\n",
            "  Using cached torch_sparse-0.6.17.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_scatter (from torch-geometric-temporal)\n",
            "  Using cached torch_scatter-2.1.1.tar.gz (107 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch_geometric (from torch-geometric-temporal)\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-geometric-temporal) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torch-geometric-temporal) (17.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-geometric-temporal) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal, torch_geometric, torch_scatter, torch_sparse\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=97af22abd717c2e9eefd4b19cc952aabd4cf0f8f74fed06034a1be134024c62b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=fcd21c5641b699521a34756308e0eb1a367a790292debcb33e06a9a8bf3f01f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=491866 sha256=2519bcaf8db2b366d850c13659da480a08d1081407b2941527df027e7390ec12\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\n",
            "  Building wheel for torch_sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_sparse: filename=torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl size=1053726 sha256=25a74b84023abc2b142367ebbdc5cefe034aa00a5b3dcc2ad57dea543346e681\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/25/e7/037b58fa47ba781444fd101a2f06c63a9d4e967ca6b910c53a\n",
            "Successfully built torch-geometric-temporal torch_geometric torch_scatter torch_sparse\n",
            "Installing collected packages: torch_scatter, torch_sparse, pandas, torch_geometric, torch-geometric-temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.3 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5 torch-geometric-temporal-0.54.0 torch_geometric-2.3.1 torch_scatter-2.1.1 torch_sparse-0.6.17\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip install torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN2\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "# GPU support\n",
        "DEVICE = torch.device('cuda') # cuda\n",
        "shuffle=True\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "_9_1Hzq-pc6k"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    def tqdm(iterable):\n",
        "        return iterable\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric_temporal.nn.recurrent import TGCN\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "loader = ChickenpoxDatasetLoader()\n",
        "\n",
        "dataset = loader.get_dataset()\n",
        "\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)\n",
        "\n",
        "class RecurrentGCN(torch.nn.Module):\n",
        "    def __init__(self, node_features):\n",
        "        super(RecurrentGCN, self).__init__()\n",
        "        self.recurrent = TGCN(node_features, 32)\n",
        "        self.linear = torch.nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight, prev_hidden_state):\n",
        "        h = self.recurrent(x, edge_index, edge_weight, prev_hidden_state)\n",
        "        y = F.relu(h)\n",
        "        y = self.linear(y)\n",
        "        return y, h\n",
        "\n",
        "model = RecurrentGCN(node_features = 4)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in tqdm(range(50)):\n",
        "    cost = 0\n",
        "    hidden_state = None\n",
        "    for time, snapshot in enumerate(train_dataset):\n",
        "        y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr,hidden_state)\n",
        "        cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "    cost = cost / (time+1)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "model.eval()\n",
        "cost = 0\n",
        "hidden_state = None\n",
        "for time, snapshot in enumerate(test_dataset):\n",
        "    y_hat, hidden_state = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr, hidden_state)\n",
        "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
        "cost = cost / (time+1)\n",
        "cost = cost.item()\n",
        "print(\"MSE: {:.4f}\".format(cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdlYr4KnprOr",
        "outputId": "248581f7-ab5b-415d-891f-ed31ece959fc"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:28<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.9937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ewruGCyaCn",
        "outputId": "94d85b3d-a0d4-4fdf-f164-0fdf8c50cba3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class ASLDatasetLoader:\n",
        "    def __init__(self, directory_path):\n",
        "        self.directory_path = directory_path\n",
        "        self.sign_to_label = self._create_sign_to_label_map()\n",
        "\n",
        "    def _create_sign_to_label_map(self):\n",
        "        signs = [os.path.splitext(filename)[0] for filename in os.listdir(self.directory_path)]\n",
        "        return {sign: i for i, sign in enumerate(signs)}\n",
        "\n",
        "    def _read_file_data(self, file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1):\n",
        "        \"\"\"\n",
        "        Augment the frame data with random rotation, translation, and scaling.\n",
        "\n",
        "        :param frame_data: Dictionary containing frame landmarks and deltas.\n",
        "        :param rotation_range: Maximum rotation angle in degrees.\n",
        "        :param translation_range: Maximum translation as a fraction of landmark range.\n",
        "        :param scaling_range: Maximum scaling factor.\n",
        "        :return: Augmented frame data.\n",
        "        \"\"\"\n",
        "        landmarks = np.array(frame_data[\"landmarks\"])\n",
        "        centroid = np.mean(landmarks, axis=0)\n",
        "\n",
        "        # Random rotation\n",
        "        theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(theta), -np.sin(theta)],\n",
        "            [np.sin(theta), np.cos(theta)]\n",
        "        ])\n",
        "        landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n",
        "\n",
        "        # Random translation\n",
        "        max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n",
        "        translations = np.random.uniform(-max_translation, max_translation)\n",
        "        landmarks += translations\n",
        "\n",
        "        # Random scaling\n",
        "        scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n",
        "        landmarks = centroid + scale * (landmarks - centroid)\n",
        "\n",
        "        frame_data[\"landmarks\"] = landmarks.tolist()\n",
        "        return frame_data\n",
        "\n",
        "    # AUGMENT DATA #2\n",
        "    # def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1, jitter_sigma=0.01, shear_range=0.1):\n",
        "    #     \"\"\"\n",
        "    #     Augment the frame data with random rotation, translation, scaling, jittering, mirroring, and shearing.\n",
        "\n",
        "    #     :param frame_data: Dictionary containing frame landmarks and deltas.\n",
        "    #     :param rotation_range: Maximum rotation angle in degrees.\n",
        "    #     :param translation_range: Maximum translation as a fraction of landmark range.\n",
        "    #     :param scaling_range: Maximum scaling factor.\n",
        "    #     :param jitter_sigma: Standard deviation for the jitter noise.\n",
        "    #     :param shear_range: Maximum shear factor.\n",
        "    #     :return: Augmented frame data.\n",
        "    #     \"\"\"\n",
        "    #     landmarks = np.array(frame_data[\"landmarks\"])\n",
        "    #     centroid = np.mean(landmarks, axis=0)\n",
        "\n",
        "    #     # Random rotation\n",
        "    #     theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n",
        "    #     rotation_matrix = np.array([\n",
        "    #         [np.cos(theta), -np.sin(theta)],\n",
        "    #         [np.sin(theta), np.cos(theta)]\n",
        "    #     ])\n",
        "    #     landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n",
        "\n",
        "    #     # Random translation\n",
        "    #     max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n",
        "    #     translations = np.random.uniform(-max_translation, max_translation)\n",
        "    #     landmarks += translations\n",
        "\n",
        "    #     # Random scaling\n",
        "    #     scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n",
        "    #     landmarks = centroid + scale * (landmarks - centroid)\n",
        "\n",
        "    #     # Jittering\n",
        "    #     jitter = np.random.normal(0, jitter_sigma, landmarks.shape)\n",
        "    #     landmarks += jitter\n",
        "\n",
        "    #     # Mirroring (Assuming that the landmarks represent a hand and x-axis is the relevant axis for mirroring)\n",
        "    #     if np.random.rand() > 0.5:\n",
        "    #         landmarks[:, 0] = -landmarks[:, 0]\n",
        "\n",
        "    #     # Random shearing\n",
        "    #     shear = np.random.uniform(-shear_range, shear_range)\n",
        "    #     shear_matrix = np.array([\n",
        "    #         [1, shear],\n",
        "    #         [0, 1]\n",
        "    #     ])\n",
        "    #     landmarks = np.dot(landmarks - centroid, shear_matrix) + centroid\n",
        "\n",
        "    #     # Random Non-linear Distortion (Optional, you can uncomment if you'd like to experiment with this)\n",
        "    #     # distortion = np.random.normal(0, 0.01, landmarks.shape)\n",
        "    #     # landmarks += distortion * landmarks\n",
        "\n",
        "    #     frame_data[\"landmarks\"] = landmarks.tolist()\n",
        "    #     return frame_data\n",
        "\n",
        "    ## AUGMENT DATA 3\n",
        "    # def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05,\n",
        "    #               scaling_range=0.1, resample_range=(0.5, 1.5), masking_prob=0.1):\n",
        "    #     \"\"\"\n",
        "    #     Augment the frame data with random rotation, translation, scaling, and temporal alterations.\n",
        "\n",
        "    #     :param frame_data: Dictionary containing frame landmarks and deltas.\n",
        "    #     :param rotation_range: Maximum rotation angle in degrees.\n",
        "    #     :param translation_range: Maximum translation as a fraction of landmark range.\n",
        "    #     :param scaling_range: Maximum scaling factor.\n",
        "    #     :param resample_range: Tuple of (min, max) scaling for random resampling.\n",
        "    #     :param masking_prob: Probability of masking a given landmark.\n",
        "    #     :return: Augmented frame data.\n",
        "    #     \"\"\"\n",
        "    #     landmarks = np.array(frame_data[\"landmarks\"])\n",
        "\n",
        "    #     print(\"Shape of landmarks before resampling:\", np.array(frame_data[\"landmarks\"]).shape)\n",
        "\n",
        "    #     # Random Resampling\n",
        "    #     resample_factor = np.random.uniform(resample_range[0], resample_range[1])\n",
        "    #     resampled_length = int(len(landmarks) * resample_factor)\n",
        "    #     resampled_landmarks = np.zeros((resampled_length, landmarks.shape[1]))\n",
        "\n",
        "    #     for dim in range(landmarks.shape[1]):\n",
        "    #         resampled_landmarks[:, dim] = np.interp(\n",
        "    #             np.linspace(0, len(landmarks) - 1, resampled_length),\n",
        "    #             np.arange(len(landmarks)),\n",
        "    #             landmarks[:, dim]\n",
        "    #         )\n",
        "\n",
        "    #     landmarks = resampled_landmarks\n",
        "\n",
        "    #     print(\"Shape of landmarks after resampling:\", landmarks.shape)\n",
        "\n",
        "    #     # Check for NaN values after resampling\n",
        "    #     if np.isnan(landmarks).any():\n",
        "    #         print(\"Warning: NaN values detected after resampling.\")\n",
        "    #         landmarks = np.nan_to_num(landmarks)\n",
        "\n",
        "    #     # Recalculate the deltas based on the new resampled landmarks\n",
        "    #     deltas = np.diff(landmarks, axis=0)\n",
        "    #     print(\"Shape of deltas after calculation:\", deltas.shape)\n",
        "    #     # Pad deltas to ensure it's the same shape as landmarks\n",
        "    #     deltas = np.vstack([deltas, np.zeros((1, landmarks.shape[1]))])\n",
        "\n",
        "\n",
        "\n",
        "    #     centroid = np.nanmean(landmarks, axis=0)\n",
        "\n",
        "    #     # Random Masking\n",
        "    #     mask = np.random.choice([True, False], size=landmarks.shape[0], p=[1-masking_prob, masking_prob])\n",
        "    #     landmarks[mask] = np.nan\n",
        "\n",
        "    #     centroid = np.nanmean(landmarks, axis=0)\n",
        "\n",
        "    #     # Random rotation\n",
        "    #     theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n",
        "    #     rotation_matrix = np.array([\n",
        "    #         [np.cos(theta), -np.sin(theta)],\n",
        "    #         [np.sin(theta), np.cos(theta)]\n",
        "    #     ])\n",
        "    #     landmarks_rot = np.dot(landmarks - centroid, rotation_matrix) + centroid\n",
        "    #     landmarks = np.where(np.isnan(landmarks), landmarks, landmarks_rot)\n",
        "\n",
        "    #     # Random translation\n",
        "    #     max_translation = translation_range * (np.nanmax(landmarks, axis=0) - np.nanmin(landmarks, axis=0))\n",
        "\n",
        "    #     # Handle potential NaN or infinite values\n",
        "    #     if np.isnan(max_translation).any() or np.isinf(max_translation).any():\n",
        "    #         print(\"Warning: NaN or infinite values detected in max_translation.\")\n",
        "    #         max_translation = np.nan_to_num(max_translation)\n",
        "\n",
        "    #     translations = np.random.uniform(-max_translation, max_translation)\n",
        "    #     landmarks += translations\n",
        "\n",
        "    #     # Random scaling\n",
        "    #     scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n",
        "    #     landmarks_scale = centroid + scale * (landmarks - centroid)\n",
        "    #     landmarks = np.where(np.isnan(landmarks), landmarks, landmarks_scale)\n",
        "\n",
        "    #     frame_data[\"landmarks\"] = landmarks.tolist()\n",
        "    #     return frame_data\n",
        "\n",
        "    # def _create_graph_from_frame(self, sign_name, frame_data):\n",
        "    #     landmarks = frame_data[\"landmarks\"]\n",
        "    #     deltas = frame_data[\"deltas\"]\n",
        "\n",
        "    #     # Create edges assuming landmarks are connected in sequence.\n",
        "    #     # For a more complex hand structure, this needs to be adapted.\n",
        "    #     edges = [[i, i+1] for i in range(len(landmarks) - 1)]\n",
        "\n",
        "    #     edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    #     x = torch.tensor(np.hstack((landmarks, deltas)), dtype=torch.float)\n",
        "    #     y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n",
        "\n",
        "    #     return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "    # def _create_graph_from_frame(self, sign_name, frame_data):\n",
        "    #     landmarks = np.array(frame_data[\"landmarks\"])\n",
        "    #     deltas = np.array(frame_data[\"deltas\"])\n",
        "\n",
        "    #     # Create edges assuming landmarks are connected in sequence.\n",
        "    #     # For a more complex hand structure, this needs to be adapted.\n",
        "    #     edges = [[i, i+1] for i in range(len(landmarks) - 1)]\n",
        "\n",
        "    #     # Adjust lengths for concatenation\n",
        "    #     n_landmarks = len(landmarks)\n",
        "    #     landmarks = landmarks[:n_landmarks-1]\n",
        "    #     deltas = deltas[:n_landmarks-1]\n",
        "\n",
        "    #     edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    #     x = torch.tensor(np.hstack((landmarks, deltas)), dtype=torch.float)\n",
        "    #     y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n",
        "\n",
        "    #     return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "    def _create_graph_from_frame(self, sign_name, frame_data):\n",
        "        landmarks = np.array(frame_data[\"landmarks\"])\n",
        "        deltas = np.array(frame_data[\"deltas\"])\n",
        "\n",
        "        # Adjust lengths for concatenation\n",
        "        n_landmarks = len(landmarks)\n",
        "        landmarks = landmarks[:n_landmarks-1]\n",
        "        deltas = deltas[:n_landmarks-1]\n",
        "\n",
        "        # Create edges based on the number of available landmarks (or nodes)\n",
        "        edges = [[i, i+1] for i in range(len(landmarks) - 1)]\n",
        "\n",
        "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "        x = torch.tensor(np.hstack((landmarks, deltas)), dtype=torch.float)\n",
        "        y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n",
        "\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "\n",
        "    def get_dataset(self, augment=False):\n",
        "        dataset = []\n",
        "\n",
        "        for filename in os.listdir(self.directory_path):\n",
        "            sign_name = os.path.splitext(filename)[0]\n",
        "            file_path = os.path.join(self.directory_path, filename)\n",
        "            sign_data = self._read_file_data(file_path)\n",
        "\n",
        "            for frame_data in sign_data[\"frames\"]:\n",
        "                if augment:\n",
        "                  frame_data = self._augment_data(frame_data)\n",
        "                graph_data = self._create_graph_from_frame(sign_name, frame_data)\n",
        "\n",
        "                dataset.append(graph_data)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def number_of_classes(self):\n",
        "        return len(self.sign_to_label)"
      ],
      "metadata": {
        "id": "LifBvD3D4t4C"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
        "\n",
        "class GraphClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes, dropout_rate=0.5):\n",
        "        super(GraphClassifier, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 128)\n",
        "        self.bn1 = BatchNorm(128)\n",
        "        self.dropout1 = torch.nn.Dropout(dropout_rate)  # Dropout after first layer\n",
        "        self.conv2 = GCNConv(128, 64)\n",
        "        self.bn2 = BatchNorm(64)\n",
        "        self.dropout2 = torch.nn.Dropout(dropout_rate)  # Dropout after second layer\n",
        "        self.fc = torch.nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # First GCN layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        #x = F.relu(x)          # Use ReLU\n",
        "        x = F.leaky_relu(x)  # Use LeakyReLU instead of ReLU\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Second GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Global pooling across nodes\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "\n",
        "        # Final classification layer\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "XpmOnloG40DP"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def stratified_data_split(data_list, test_size=0.2):\n",
        "    # Extract labels from data list\n",
        "    labels = [data.y.item() for data in data_list]\n",
        "\n",
        "    # Use sklearn's train_test_split with stratify option\n",
        "    train_data, test_data = train_test_split(data_list, test_size=test_size, stratify=labels, random_state=42)\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "def train():\n",
        "    directory_path = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/Datasets/ASL\"\n",
        "    loader = ASLDatasetLoader(directory_path)\n",
        "\n",
        "    # Create the entire dataset without augmentation and then perform stratified split\n",
        "    data_list = loader.get_dataset()\n",
        "    train_dataset, test_dataset = stratified_data_split(data_list, test_size=0.2)\n",
        "\n",
        "    # Now augment only the training dataset\n",
        "    augmented_train_dataset = loader.get_dataset(augment=True)\n",
        "\n",
        "    num_classes = loader.number_of_classes()\n",
        "\n",
        "    train_labels = [data.y.item() for data in train_dataset]\n",
        "    test_labels = [data.y.item() for data in test_dataset]\n",
        "\n",
        "    print(\"Training label distribution:\", Counter(train_labels))\n",
        "    print(\"Test label distribution:\", Counter(test_labels))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = GraphClassifier(num_node_features=4, num_classes=num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n",
        "\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = F.nll_loss(out, batch.y)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if np.isnan(loss.item()):\n",
        "                print(\"Warning: NaN loss detected!\")\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n",
        "\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(batch).max(dim=1)[1]\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(batch.y.cpu().numpy())\n",
        "            correct += pred.eq(batch.y).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {correct / len(test_dataset)}\")\n",
        "    print(\"Sample predictions:\", all_preds[:20])\n",
        "    print(\"Sample true labels:\", all_labels[:20])"
      ],
      "metadata": {
        "id": "6QYi0OpiBuRK"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr2PlwLy5M6H",
        "outputId": "1ab29255-c25e-4a9a-865a-ecbfda96d5a1"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training label distribution: Counter({0: 402, 12: 363, 10: 298, 18: 282, 3: 269, 5: 265, 6: 258, 17: 247, 14: 246, 15: 243, 16: 243, 9: 236, 2: 223, 8: 220, 4: 215, 7: 214, 13: 210, 19: 203, 1: 199, 11: 199})\n",
            "Test label distribution: Counter({0: 100, 12: 91, 10: 75, 18: 70, 3: 67, 5: 66, 6: 65, 17: 62, 14: 62, 15: 61, 16: 60, 9: 59, 2: 56, 8: 55, 4: 54, 7: 53, 13: 52, 19: 51, 11: 50, 1: 50})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.747401860695851\n",
            "Epoch 1, Loss: 2.4783026176162912\n",
            "Epoch 2, Loss: 2.344883905935891\n",
            "Epoch 3, Loss: 2.254833359507066\n",
            "Epoch 4, Loss: 2.1827439069747925\n",
            "Epoch 5, Loss: 2.120556626893297\n",
            "Epoch 6, Loss: 2.0770003176942655\n",
            "Epoch 7, Loss: 2.037682886365094\n",
            "Epoch 8, Loss: 1.987620001352286\n",
            "Epoch 9, Loss: 1.968819334537168\n",
            "Epoch 10, Loss: 1.9221996325480788\n",
            "Epoch 11, Loss: 1.9185850235480297\n",
            "Epoch 12, Loss: 1.8770140318930904\n",
            "Epoch 13, Loss: 1.8481386764140069\n",
            "Epoch 14, Loss: 1.8230585606792304\n",
            "Epoch 15, Loss: 1.8296506442601168\n",
            "Epoch 16, Loss: 1.7942481335205367\n",
            "Epoch 17, Loss: 1.7383391676069815\n",
            "Epoch 18, Loss: 1.7407683594317376\n",
            "Epoch 19, Loss: 1.7164079637467107\n",
            "Epoch 20, Loss: 1.705352722843991\n",
            "Epoch 21, Loss: 1.6862711725355704\n",
            "Epoch 22, Loss: 1.6609583270700672\n",
            "Epoch 23, Loss: 1.6625267953812322\n",
            "Epoch 24, Loss: 1.653977477097813\n",
            "Epoch 25, Loss: 1.6379668410820296\n",
            "Epoch 26, Loss: 1.650643605220167\n",
            "Epoch 27, Loss: 1.6498609773720367\n",
            "Epoch 28, Loss: 1.6114877537836003\n",
            "Epoch 29, Loss: 1.615409688104557\n",
            "Epoch 30, Loss: 1.608718377125414\n",
            "Epoch 31, Loss: 1.625599738163284\n",
            "Epoch 32, Loss: 1.6118165292317355\n",
            "Epoch 33, Loss: 1.5919614207895496\n",
            "Epoch 34, Loss: 1.5901106316832048\n",
            "Epoch 35, Loss: 1.5749953298629085\n",
            "Epoch 36, Loss: 1.5977797794945632\n",
            "Epoch 37, Loss: 1.5691803203353398\n",
            "Epoch 38, Loss: 1.5600400551964966\n",
            "Epoch 39, Loss: 1.5785720959494385\n",
            "Epoch 40, Loss: 1.5803319344037696\n",
            "Epoch 41, Loss: 1.5517918354348292\n",
            "Epoch 42, Loss: 1.5419141091877901\n",
            "Epoch 43, Loss: 1.5658456668069092\n",
            "Epoch 44, Loss: 1.5449081229258188\n",
            "Epoch 45, Loss: 1.5588182218467133\n",
            "Epoch 46, Loss: 1.5398944329611863\n",
            "Epoch 47, Loss: 1.5495608358443538\n",
            "Epoch 48, Loss: 1.5282257863237887\n",
            "Epoch 49, Loss: 1.5603950725326055\n",
            "Epoch 50, Loss: 1.5561443895478793\n",
            "Epoch 51, Loss: 1.5365647092650208\n",
            "Epoch 52, Loss: 1.5217621937582764\n",
            "Epoch 53, Loss: 1.5383605466613286\n",
            "Epoch 54, Loss: 1.5234400490416755\n",
            "Epoch 55, Loss: 1.532057961331138\n",
            "Epoch 56, Loss: 1.5354288341123847\n",
            "Epoch 57, Loss: 1.5329958871950078\n",
            "Epoch 58, Loss: 1.5185863975482652\n",
            "Epoch 59, Loss: 1.532337477690057\n",
            "Epoch 60, Loss: 1.52300649805914\n",
            "Epoch 61, Loss: 1.5086190994781783\n",
            "Epoch 62, Loss: 1.5284089430978027\n",
            "Epoch 63, Loss: 1.5140290750732905\n",
            "Epoch 64, Loss: 1.5244616715213921\n",
            "Epoch 65, Loss: 1.4935045163088208\n",
            "Epoch 66, Loss: 1.5067922306966177\n",
            "Epoch 67, Loss: 1.5260497848444348\n",
            "Epoch 68, Loss: 1.486385223231738\n",
            "Epoch 69, Loss: 1.5016714206224755\n",
            "Epoch 70, Loss: 1.4706257253508024\n",
            "Epoch 71, Loss: 1.5089608061162731\n",
            "Epoch 72, Loss: 1.504845687860175\n",
            "Epoch 73, Loss: 1.5030259987975978\n",
            "Epoch 74, Loss: 1.5089217877086205\n",
            "Epoch 75, Loss: 1.4839489286458944\n",
            "Epoch 76, Loss: 1.5000101712685596\n",
            "Epoch 77, Loss: 1.511341916609414\n",
            "Epoch 78, Loss: 1.4900585575194298\n",
            "Epoch 79, Loss: 1.4996651139440416\n",
            "Epoch 80, Loss: 1.4800953480261791\n",
            "Epoch 81, Loss: 1.5179160418389719\n",
            "Epoch 00082: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 82, Loss: 1.4693085875692247\n",
            "Epoch 83, Loss: 1.4737579947030996\n",
            "Epoch 84, Loss: 1.441779987344259\n",
            "Epoch 85, Loss: 1.4580867713010763\n",
            "Epoch 86, Loss: 1.4761857903456386\n",
            "Epoch 87, Loss: 1.441677329660971\n",
            "Epoch 88, Loss: 1.448812729572948\n",
            "Epoch 89, Loss: 1.461638242760791\n",
            "Epoch 90, Loss: 1.4407485587687432\n",
            "Epoch 91, Loss: 1.448915248430228\n",
            "Epoch 92, Loss: 1.4395237221748014\n",
            "Epoch 93, Loss: 1.445505786545669\n",
            "Epoch 94, Loss: 1.437557035231892\n",
            "Epoch 95, Loss: 1.4540948381152334\n",
            "Epoch 96, Loss: 1.4467060018943836\n",
            "Epoch 97, Loss: 1.4335750032074843\n",
            "Epoch 98, Loss: 1.4435531089577494\n",
            "Epoch 99, Loss: 1.4545593635190892\n",
            "Accuracy: 0.7084988085782367\n",
            "Sample predictions: [6, 11, 7, 2, 12, 12, 18, 18, 13, 8, 12, 3, 2, 19, 0, 19, 12, 4, 0, 5]\n",
            "Sample true labels: [4, 11, 2, 2, 12, 12, 11, 11, 13, 12, 12, 17, 2, 19, 0, 17, 12, 6, 0, 5]\n"
          ]
        }
      ]
    }
  ]
}