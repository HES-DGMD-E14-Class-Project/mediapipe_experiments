{"cells":[{"cell_type":"markdown","metadata":{"id":"lLqJy6EZtrZB"},"source":["### Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22145,"status":"ok","timestamp":1697016509179,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"},"user_tz":-60},"id":"7-ewruGCyaCn","outputId":"932eb2bd-24e4-4340-ff3f-c9d0dcd89c92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"yLRvBRGgt5Zk"},"source":["#### Install Pytorch Geometric Temporal"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oiSS4wuxZ01m","outputId":"977a2fbf-c086-4bec-fca9-95a072c1027f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu118\n","11.8\n","Collecting torch-geometric-temporal\n","  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m404.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.0.1+cu118)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.3)\n","Collecting pandas\u003c=1.3.5 (from torch-geometric-temporal)\n","  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse (from torch-geometric-temporal)\n","  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch_scatter (from torch-geometric-temporal)\n","  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch_geometric (from torch-geometric-temporal)\n","  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c=1.3.5-\u003etorch-geometric-temporal) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c=1.3.5-\u003etorch-geometric-temporal) (2023.3.post1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003etorch-geometric-temporal) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-\u003etorch-geometric-temporal) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003etorch-geometric-temporal) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003etorch-geometric-temporal) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003etorch-geometric-temporal) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003etorch-geometric-temporal) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003etorch-geometric-temporal) (17.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (4.66.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (1.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (1.2.2)\n","Requirement already satisfied: psutil\u003e=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric-\u003etorch-geometric-temporal) (5.9.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003etorch-geometric-temporal) (2.1.3)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorch_geometric-\u003etorch-geometric-temporal) (3.3.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorch_geometric-\u003etorch-geometric-temporal) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorch_geometric-\u003etorch-geometric-temporal) (2.0.6)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorch_geometric-\u003etorch-geometric-temporal) (2023.7.22)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003etorch_geometric-\u003etorch-geometric-temporal) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003etorch_geometric-\u003etorch-geometric-temporal) (3.2.0)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003etorch-geometric-temporal) (1.3.0)\n","Building wheels for collected packages: torch-geometric-temporal, torch_geometric, torch_scatter, torch_sparse\n","  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=b6d4ab638476731beaa9411e14a90de31eb7da634dd18d854033162a45c20305\n","  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=8bae0b30dfe420ac46e9e184484bf000bd25087d7e9df22df856e8b8a4857c45\n","  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n","  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=494366 sha256=906a72c3a9f09fa34c54ac2b3b49baa7f35213caff672632239fc7411ef41cb5\n","  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n"]}],"source":["!python -c \"import torch; print(torch.__version__)\"\n","!python -c \"import torch; print(torch.version.cuda)\"\n","!pip install torch-geometric-temporal"]},{"cell_type":"markdown","metadata":{"id":"zi7c7EMpsCBX"},"source":["### `ASLDatasetLoader` Class\n","\n","The `ASLDatasetLoader` class is designed for loading and processing the ASL dataset. Given a directory, it reads sign language data from JSON files and constructs graph representations suitable for graph-based neural networks. Crucially, the class converts JSON data into PyTorch Geometric (PyG) `Data` objects comprising `x` (node features), `edge_index` (graph connectivity), and `y' (labels) attributes.\n","\n","**Methods**:\n","\n","- `_create_sign_to_label_map`: Generates a mapping from sign names to unique labels.\n","\n","- `_read_file_data`: Reads data from a given JSON file.\n","\n","- `_augment_data`: Implements data augmentation by applying random rotation, translation, and scaling to landmarks, which can enhance the model's robustness.\n","\n","- `_create_graph_from_frame`: Constructs a PyG `Data` object from frame data, concentrating on hand and face landmarks. Edges are created between consecutive landmarks and between left and right hand landmarks. Additional features, like hand-to-face distances, are also computed.\n","\n","- `get_dataset`: Assembles the dataset, optionally incorporating data augmentation. The function outputs a list of PyG `Data` objects ready for graph neural network processing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LifBvD3D4t4C"},"outputs":[],"source":["import torch\n","import os\n","import json\n","import numpy as np\n","from torch_geometric.data import Data\n","\n","HAND_TO_FACE_THRESHOLD = 0.05\n","\n","class ASLDatasetLoader:\n","    def __init__(self, directory_path):\n","        self.directory_path = directory_path\n","        self.sign_to_label = self._create_sign_to_label_map()\n","\n","    def _create_sign_to_label_map(self):\n","        signs = [os.path.splitext(filename)[0] for filename in os.listdir(self.directory_path)]\n","        return {sign: i for i, sign in enumerate(signs)}\n","\n","    def _read_file_data(self, file_path):\n","        with open(file_path, 'r') as f:\n","            return json.load(f)\n","\n","    def _augment_data(self, frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1):\n","        \"\"\"\n","        Augment the frame data with random rotation, translation, and scaling.\n","\n","        :param frame_data: Dictionary containing frame landmarks and deltas.\n","        :param rotation_range: Maximum rotation angle in degrees.\n","        :param translation_range: Maximum translation as a fraction of landmark range.\n","        :param scaling_range: Maximum scaling factor.\n","        :return: Augmented frame data.\n","        \"\"\"\n","        landmarks = np.array(frame_data[\"landmarks\"])\n","        centroid = np.mean(landmarks, axis=0)\n","\n","        # Random rotation\n","        theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n","        rotation_matrix = np.array([\n","            [np.cos(theta), -np.sin(theta)],\n","            [np.sin(theta), np.cos(theta)]\n","        ])\n","        landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n","\n","        # Random translation\n","        max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n","        translations = np.random.uniform(-max_translation, max_translation)\n","        landmarks += translations\n","\n","        # Random scaling\n","        scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n","        landmarks = centroid + scale * (landmarks - centroid)\n","\n","        frame_data[\"landmarks\"] = landmarks.tolist()\n","        return frame_data\n","\n","    def _calculate_dominant_hand(self, sign_data):\n","        \"\"\"\n","        Determine the dominant hand in a sign language data sample.\n","\n","        This function analyzes the motion of both hands throughout the frames in\n","        a given sign language data sample. The dominant hand is determined based\n","        on the average magnitude and frequency of motion. The hand with the\n","        higher average magnitude or higher motion event frequency is considered\n","        dominant.\n","\n","        Returns\n","        -------\n","        str\n","            A string indicating the dominant hand. Possible return values are\n","            \"left\", \"right\", or \"ambiguous\" if no clear dominant hand can be\n","            determined.\n","\n","        Notes\n","        -----\n","        The function assumes that the order of landmarks and deltas is consistent\n","        across frames and that hands' landmarks are distinguishable in the\n","        landmark data (e.g., by their order or a separate landmark type identifier).\n","\n","        The decision criterion for dominant hand detection is heuristic and may\n","        require adjustment based on empirical results and specific use case needs.\n","        \"\"\"\n","        left_hand_motion = 0\n","        right_hand_motion = 0\n","        left_hand_motion_events = 0\n","        right_hand_motion_events = 0\n","\n","        for frame_data in sign_data[\"frames\"]:\n","            landmarks = np.array(frame_data[\"landmarks\"])\n","            deltas = np.array(frame_data[\"deltas\"])\n","            landmark_types = frame_data[\"landmark_types\"]\n","\n","            for delta, ltype in zip(deltas, landmark_types):\n","                motion_magnitude = np.linalg.norm(delta)\n","\n","                if ltype == \"L\":\n","                    left_hand_motion += motion_magnitude\n","                    if motion_magnitude \u003e 0.5:  # Threshold may need adjustment\n","                        left_hand_motion_events += 1\n","\n","                elif ltype == \"R\":\n","                    right_hand_motion += motion_magnitude\n","                    if motion_magnitude \u003e 0.5:  # Threshold may need adjustment\n","                        right_hand_motion_events += 1\n","\n","        # Combine motion magnitude and motion events to determine the dominant hand\n","        # Weights (0.5 and 0.5) might need adjustment based on empirical observation\n","        left_hand_score = 0.5 * left_hand_motion + 0.5 * left_hand_motion_events\n","        right_hand_score = 0.5 * right_hand_motion + 0.5 * right_hand_motion_events\n","\n","        return \"left\" if left_hand_score \u003e right_hand_score else \"right\"\n","\n","\n","    def _create_graph_from_frame(self, sign_name, frame_data, sign_data, landmark_types):\n","        # Calculate dominant hand\n","        dominant_hand = self._calculate_dominant_hand(sign_data)\n","\n","        # Extract landmark and delta information\n","        landmarks = np.array(frame_data[\"landmarks\"])\n","        deltas = np.array(frame_data[\"deltas\"])\n","\n","        # Add dominant hand information to node features\n","        dominant_hand_feature = [\n","            1 if ((t == \"L\" and dominant_hand == \"left\") or (t == \"R\" and dominant_hand == \"right\")) else 0\n","            for t in landmark_types\n","        ]\n","        dominant_hand_feature_2d = np.array(dominant_hand_feature)[:, np.newaxis]\n","\n","        # Compute additional features like hand-to-face and hand-to-body distances\n","        # ... (If you have additional feature creation logic, add here)\n","        hand_to_face_contact = [0] * len(landmark_types) # replace this line with actual feature creation if used\n","        hand_to_face_contact_2d = np.array(hand_to_face_contact)[:, np.newaxis]\n","\n","        # Create weights based on landmark importance\n","        weights = [2 if t == \"L\" or t == \"R\" else 1 for t in landmark_types]\n","        weights_2d = np.array(weights)[:, np.newaxis]\n","\n","        # Concatenate landmarks, deltas, importance weights, hand-to-face contact features, and dominant hand feature\n","        x = torch.tensor(np.hstack((landmarks, deltas, weights_2d, hand_to_face_contact_2d, dominant_hand_feature_2d)), dtype=torch.float)\n","        y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n","\n","        # Create edges based on the number of available landmarks (or nodes)\n","        # You might have specific logic to determine edges based on landmark types or spatial proximity\n","        edges = [[i, i + 1] for i in range(len(landmarks) - 1)]\n","\n","        # Add edges between the left and right hand landmarks\n","        for i, t1 in enumerate(landmark_types):\n","            for j, t2 in enumerate(landmark_types):\n","                if t1 in [\"L\", \"R\"] and t2 in [\"L\", \"R\"] and i != j:\n","                    edges.append([i, j])\n","\n","        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n","\n","        return Data(x=x, edge_index=edge_index, y=y)\n","\n","    def get_dataset(self, augment=False):\n","      dataset = []\n","\n","      for filename in os.listdir(self.directory_path):\n","          sign_name = os.path.splitext(filename)[0]\n","          file_path = os.path.join(self.directory_path, filename)\n","          sign_data = self._read_file_data(file_path)\n","\n","          for frame_data in sign_data[\"frames\"]:\n","              landmark_types = sign_data.get(\"landmark_types\", [\"F\", \"L\", \"P\", \"R\"])  # defaulting to all types\n","\n","              if augment:\n","                  frame_data = self._augment_data(frame_data)\n","              graph_data = self._create_graph_from_frame(sign_name, frame_data, sign_data, landmark_types)\n","\n","              dataset.append(graph_data)\n","\n","      return dataset\n","\n","    def number_of_classes(self):\n","        return len(self.sign_to_label)"]},{"cell_type":"markdown","metadata":{"id":"xooW2sogtdL1"},"source":["### `ASLGraphClassifier` Class\n","\n","The `ASLGraphClassifier`, features deeper GCN layers and additional channels to capture intricate data patterns potentially. It takes a PyG `Data` object as input, and its forward pass emits class logits.\n","\n","**Methods**:\n","\n","- `forward`: Details the forward pass, accepting a PyG `Data` object. Two GCN layers with subsequent batch normalization and dropout layers process the input. Post global max-pooling, two linear layers coupled with dropout ensure final classification, leading to log-softmax outputs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAslUK79VVV6"},"outputs":[],"source":["import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_max_pool, global_mean_pool\n","\n","class ASLGraphClassifier(torch.nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(ASLGraphClassifier, self).__init__()\n","        self.conv1 = GCNConv(num_features, 512)\n","        self.conv2 = GCNConv(512, 1024)\n","        self.conv3 = GCNConv(1024, 1024)  # Added layer\n","        self.bn1 = torch.nn.BatchNorm1d(512)\n","        self.bn2 = torch.nn.BatchNorm1d(1024)\n","        self.bn3 = torch.nn.BatchNorm1d(1024)  # Added layer\n","        self.lin1 = torch.nn.Linear(1024, 512)\n","        self.lin2 = torch.nn.Linear(512, 256)\n","        self.lin3 = torch.nn.Linear(256, num_classes)  # Added layer\n","        self.dropout = torch.nn.Dropout(p=0.2)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        x = self.dropout(x)\n","        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n","        x = self.dropout(x)\n","        x = F.relu(self.bn3(self.conv3(x, edge_index)))  # Added layer\n","        x = self.dropout(x)\n","        x = global_max_pool(x, batch)\n","        x = F.relu(self.lin1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.lin2(x))  # Added layer\n","        x = self.dropout(x)\n","        x = self.lin3(x)  # Modified layer\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdBGsFveWcbF"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch_geometric.loader import DataLoader\n","from collections import Counter\n","import random\n","\n","EPOCHS = 200\n","LEARNING_RATE = 0.001\n","\n","\n","def stratified_data_split(data_list, test_size=0.2):\n","    \"\"\"\n","    This function splits a dataset into training and testing subsets, preserving\n","    the class distribution by leveraging the stratification capabilities of\n","    `train_test_split` from `sklearn`. Stratification helps with potential class\n","    imbalances.\n","    \"\"\"\n","    # Extract labels from data list\n","    labels = [data.y.item() for data in data_list]\n","\n","    # Use sklearn's train_test_split with stratify option\n","    train_data, test_data = train_test_split(data_list, test_size=test_size, stratify=labels, random_state=42)\n","\n","    return train_data, test_data\n","\n","\n","def validate(loader, model, device):\n","    \"\"\"\n","    Used to evaluate the model on validation/test data, computing accuracy as a\n","    performance metric, and offering insights into the model's efficacy.\n","    \"\"\"\n","    model.eval()\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        with torch.no_grad():\n","            out = model(data)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == data.y).sum())\n","    return correct / len(loader.dataset)\n","\n","def train(loader):\n","    \"\"\"\n","    The `train` function establishes the training loop for the graph-based\n","    neural network. It enacts typical training loop tasks like logging\n","    epoch-wise loss, validation, and early stopping.\n","\n","    The function also harnesses schedulers, regularization techniques, and\n","    gradient clipping to ensure smooth and optimal training.\n","    \"\"\"\n","\n","    # Create the entire dataset without augmentation and then perform stratified split\n","    data_list = loader.get_dataset()\n","    train_dataset, test_dataset = stratified_data_split(data_list, test_size=0.2)\n","\n","    # Now augment only the training dataset\n","    augmented_train_dataset = loader.get_dataset(augment=True)\n","\n","    num_classes = loader.number_of_classes()\n","\n","    train_labels = [data.y.item() for data in train_dataset]\n","    test_labels = [data.y.item() for data in test_dataset]\n","\n","    print(\"Training label distribution:\", Counter(train_labels))\n","    print(\"Test label distribution:\", Counter(test_labels))\n","\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    num_features = train_dataset[0].x.size(1)\n","    model = ASLGraphClassifier(num_features=num_features, num_classes=num_classes).to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=5, verbose=True)\n","\n","    max_epochs_without_improvement = 20\n","    epochs_without_improvement = 0\n","    best_val_accuracy = 0\n","\n","    model.train()\n","    for epoch in range(EPOCHS):\n","        total_loss = 0\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            out = model(batch)\n","            loss = F.nll_loss(out, batch.y)\n","            loss.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","            # Check for NaN loss\n","            if np.isnan(loss.item()):\n","                print(\"Warning: NaN loss detected!\")\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Epoch {epoch}, Loss: {avg_loss}\")\n","\n","        val_accuracy = validate(test_loader, model, device)\n","        scheduler.step(val_accuracy)\n","\n","        if val_accuracy \u003e best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        if epochs_without_improvement \u003e= max_epochs_without_improvement:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","    model.eval()\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for batch in test_loader:\n","        batch = batch.to(device)\n","        with torch.no_grad():\n","            pred = model(batch).max(dim=1)[1]\n","            all_preds.extend(pred.cpu().numpy())\n","            all_labels.extend(batch.y.cpu().numpy())\n","            correct += pred.eq(batch.y).sum().item()\n","\n","    accuracy = correct / len(test_dataset)\n","\n","    print(f\"Accuracy: {accuracy}\")\n","    print(\"Sample predictions:\", all_preds[:20])\n","    print(\"Sample true labels:\", all_labels[:20])\n","\n","    return model, all_preds, all_labels, accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"rr2PlwLy5M6H"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training label distribution: Counter({190: 438, 145: 430, 88: 430, 93: 420, 208: 402, 121: 400, 209: 363, 76: 346, 56: 338, 92: 338, 180: 332, 34: 330, 16: 324, 172: 323, 182: 316, 31: 310, 24: 309, 195: 308, 183: 307, 192: 306, 148: 304, 215: 298, 10: 297, 150: 297, 130: 296, 29: 295, 113: 295, 151: 295, 79: 294, 143: 293, 149: 292, 44: 290, 64: 289, 106: 288, 89: 286, 210: 282, 1: 279, 147: 279, 169: 278, 107: 278, 191: 278, 52: 277, 114: 277, 13: 276, 77: 275, 98: 274, 4: 274, 19: 274, 170: 273, 205: 273, 81: 271, 206: 270, 154: 270, 199: 270, 46: 270, 212: 269, 65: 269, 32: 268, 2: 266, 211: 265, 55: 265, 36: 265, 152: 264, 7: 263, 14: 263, 35: 263, 60: 262, 73: 262, 139: 262, 119: 262, 204: 261, 133: 261, 94: 261, 43: 260, 216: 258, 68: 258, 66: 257, 178: 256, 125: 255, 30: 255, 138: 255, 179: 254, 157: 254, 59: 253, 33: 253, 181: 252, 47: 251, 53: 250, 126: 250, 120: 250, 186: 250, 129: 249, 15: 249, 142: 247, 219: 247, 40: 247, 62: 247, 164: 247, 41: 247, 162: 246, 102: 246, 213: 246, 124: 244, 100: 244, 72: 243, 20: 243, 217: 243, 203: 242, 218: 242, 207: 242, 96: 241, 137: 241, 166: 241, 174: 240, 161: 240, 91: 239, 134: 239, 104: 238, 135: 238, 202: 238, 184: 238, 158: 237, 194: 237, 214: 236, 197: 236, 165: 236, 168: 235, 18: 235, 122: 234, 67: 234, 85: 234, 45: 234, 78: 234, 37: 234, 42: 234, 185: 234, 82: 233, 6: 233, 187: 231, 111: 230, 176: 230, 144: 230, 26: 229, 198: 229, 127: 229, 69: 229, 167: 227, 153: 226, 84: 226, 90: 226, 70: 226, 0: 225, 140: 224, 156: 224, 163: 224, 118: 223, 22: 223, 141: 223, 220: 223, 38: 222, 58: 222, 5: 222, 71: 222, 87: 222, 200: 222, 101: 222, 12: 221, 222: 220, 57: 219, 95: 219, 11: 218, 17: 218, 25: 218, 175: 218, 8: 217, 49: 216, 109: 215, 225: 215, 146: 214, 223: 214, 115: 214, 99: 213, 48: 212, 27: 211, 50: 211, 171: 210, 221: 210, 123: 209, 54: 209, 132: 209, 51: 209, 21: 208, 160: 208, 75: 208, 39: 207, 201: 206, 189: 206, 188: 206, 9: 206, 105: 205, 177: 204, 136: 204, 112: 204, 86: 204, 226: 203, 23: 202, 196: 202, 108: 202, 116: 202, 155: 201, 80: 201, 224: 199, 173: 199, 227: 199, 83: 198, 128: 198, 117: 198, 61: 197, 131: 197, 74: 197, 63: 196, 193: 195, 28: 194, 3: 193, 110: 193, 103: 188, 97: 185, 159: 182})\n","Test label distribution: Counter({190: 109, 145: 108, 88: 107, 93: 105, 121: 100, 208: 100, 209: 91, 76: 86, 92: 85, 56: 84, 34: 83, 180: 83, 16: 81, 172: 81, 182: 79, 31: 78, 195: 77, 192: 77, 24: 77, 183: 77, 148: 76, 215: 75, 113: 74, 130: 74, 151: 74, 10: 74, 79: 74, 150: 74, 29: 74, 143: 73, 44: 73, 149: 73, 64: 72, 106: 72, 89: 72, 1: 70, 147: 70, 210: 70, 169: 70, 107: 70, 77: 69, 191: 69, 19: 69, 13: 69, 114: 69, 52: 69, 205: 68, 170: 68, 98: 68, 154: 68, 81: 68, 4: 68, 212: 67, 65: 67, 206: 67, 32: 67, 2: 67, 199: 67, 46: 67, 14: 66, 73: 66, 139: 66, 55: 66, 35: 66, 60: 66, 7: 66, 211: 66, 152: 66, 36: 66, 119: 65, 216: 65, 133: 65, 204: 65, 43: 65, 94: 65, 178: 64, 68: 64, 125: 64, 66: 64, 138: 64, 157: 64, 30: 64, 33: 63, 186: 63, 181: 63, 47: 63, 120: 63, 179: 63, 53: 63, 59: 63, 41: 62, 219: 62, 142: 62, 164: 62, 15: 62, 40: 62, 129: 62, 213: 62, 126: 62, 102: 62, 62: 62, 162: 62, 72: 61, 124: 61, 20: 61, 217: 61, 203: 61, 100: 61, 207: 61, 218: 61, 134: 60, 91: 60, 96: 60, 166: 60, 161: 60, 137: 60, 184: 60, 174: 60, 165: 59, 122: 59, 18: 59, 158: 59, 194: 59, 67: 59, 202: 59, 135: 59, 104: 59, 214: 59, 42: 59, 168: 59, 85: 59, 197: 59, 6: 58, 37: 58, 187: 58, 78: 58, 82: 58, 185: 58, 45: 58, 167: 57, 198: 57, 144: 57, 176: 57, 111: 57, 127: 57, 153: 57, 69: 57, 26: 57, 38: 56, 163: 56, 0: 56, 84: 56, 58: 56, 156: 56, 118: 56, 87: 56, 141: 56, 140: 56, 22: 56, 70: 56, 200: 56, 220: 56, 90: 56, 175: 55, 12: 55, 222: 55, 95: 55, 71: 55, 101: 55, 5: 55, 17: 55, 57: 55, 49: 54, 25: 54, 146: 54, 11: 54, 109: 54, 8: 54, 225: 54, 171: 53, 115: 53, 27: 53, 50: 53, 99: 53, 223: 53, 48: 53, 21: 52, 51: 52, 75: 52, 39: 52, 9: 52, 132: 52, 160: 52, 54: 52, 123: 52, 221: 52, 196: 51, 177: 51, 226: 51, 112: 51, 105: 51, 201: 51, 86: 51, 136: 51, 189: 51, 188: 51, 116: 51, 108: 51, 173: 50, 224: 50, 155: 50, 128: 50, 23: 50, 227: 50, 80: 50, 74: 49, 63: 49, 131: 49, 28: 49, 117: 49, 61: 49, 83: 49, 110: 48, 3: 48, 193: 48, 103: 47, 97: 46, 159: 45})\n","Epoch 0, Loss: 3.9872016267275687\n","Epoch 1, Loss: 2.9852403128369254\n","Epoch 2, Loss: 2.6398905010831886\n","Epoch 3, Loss: 2.538015502243645\n","Epoch 4, Loss: 2.4774158882058184\n","Epoch 5, Loss: 2.4484297812557165\n","Epoch 6, Loss: 2.3541017346702544\n","Epoch 7, Loss: 2.3330601340697217\n","Epoch 8, Loss: 2.2746711405302293\n","Epoch 9, Loss: 2.2181557025160914\n","Epoch 10, Loss: 2.2387996680449795\n","Epoch 11, Loss: 2.174324619911405\n","Epoch 12, Loss: 2.172469684257809\n","Epoch 13, Loss: 2.14880202504486\n","Epoch 14, Loss: 2.1289360556206685\n","Epoch 15, Loss: 2.12460961279931\n","Epoch 16, Loss: 2.09672142192511\n","Epoch 17, Loss: 2.092749023289414\n","Epoch 18, Loss: 2.0950147756272828\n","Epoch 19, Loss: 2.062579255666792\n","Epoch 20, Loss: 2.0697726807575454\n","Epoch 21, Loss: 2.079782463614379\n","Epoch 22, Loss: 2.056391745014826\n","Epoch 23, Loss: 2.0043747810776256\n","Epoch 24, Loss: 2.0293930041998673\n","Epoch 25, Loss: 1.9944471015827863\n","Epoch 26, Loss: 2.006083890114175\n","Epoch 27, Loss: 1.968510477371905\n","Epoch 28, Loss: 1.9812484579124\n","Epoch 29, Loss: 1.9808702876781892\n","Epoch 00030: reducing learning rate of group 0 to 7.0000e-04.\n","Epoch 30, Loss: 1.8083269882175224\n","Epoch 31, Loss: 1.7720035665254685\n","Epoch 32, Loss: 1.770242759294257\n","Epoch 33, Loss: 1.7632140929519895\n","Epoch 34, Loss: 1.7389188935566864\n","Epoch 35, Loss: 1.729988672381939\n","Epoch 36, Loss: 1.729489872342513\n","Epoch 37, Loss: 1.725672363494494\n","Epoch 38, Loss: 1.7160447331083353\n","Epoch 39, Loss: 1.7296310600286686\n","Epoch 00040: reducing learning rate of group 0 to 4.9000e-04.\n","Epoch 40, Loss: 1.623371494953946\n","Epoch 41, Loss: 1.5939688504852862\n","Epoch 42, Loss: 1.5746854431611679\n","Epoch 43, Loss: 1.5677264767605863\n","Epoch 44, Loss: 1.5581970517410524\n","Epoch 45, Loss: 1.5591637621082066\n","Epoch 46, Loss: 1.5381309286744362\n","Epoch 47, Loss: 1.5509406274351814\n","Epoch 48, Loss: 1.5579659689421845\n","Epoch 49, Loss: 1.550553908158264\n","Epoch 50, Loss: 1.5397643276623316\n","Epoch 00051: reducing learning rate of group 0 to 3.4300e-04.\n","Epoch 51, Loss: 1.454352227494516\n","Epoch 52, Loss: 1.4177159463060165\n","Epoch 53, Loss: 1.4136048655332245\n","Epoch 54, Loss: 1.4214257935828776\n","Epoch 55, Loss: 1.4122590461671185\n","Epoch 56, Loss: 1.4012685138111665\n","Epoch 57, Loss: 1.4026369504979745\n","Epoch 58, Loss: 1.3926644564886541\n","Epoch 59, Loss: 1.39062846662768\n","Epoch 60, Loss: 1.3868958473811372\n","Epoch 00061: reducing learning rate of group 0 to 2.4010e-04.\n","Epoch 61, Loss: 1.3308056173925007\n","Epoch 62, Loss: 1.3106544921453358\n","Epoch 63, Loss: 1.3049322534657548\n","Epoch 64, Loss: 1.295263911962913\n","Epoch 65, Loss: 1.2933023801838053\n","Epoch 66, Loss: 1.2908373114956362\n","Epoch 67, Loss: 1.2937271626637792\n","Epoch 68, Loss: 1.286624139274735\n","Epoch 69, Loss: 1.2794409355223346\n","Epoch 70, Loss: 1.273473003064085\n","Epoch 71, Loss: 1.2729376518813855\n","Epoch 72, Loss: 1.2692742333581797\n","Epoch 73, Loss: 1.2740192346354786\n","Epoch 74, Loss: 1.2761650590624667\n","Epoch 75, Loss: 1.275028522878902\n","Epoch 76, Loss: 1.2705484093548147\n","Epoch 77, Loss: 1.2715375155866786\n","Epoch 78, Loss: 1.2735910474210725\n","Epoch 00079: reducing learning rate of group 0 to 1.6807e-04.\n","Epoch 79, Loss: 1.2188760827383303\n","Epoch 80, Loss: 1.2042925280073415\n"]}],"source":["directory_path = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/Datasets/ASL\"\n","loader = ASLDatasetLoader(directory_path)\n","\n","model, all_preds, all_labels, accuracy = train(loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMrYkTs89Q7O"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# Convert lists to numpy arrays for compatibility with sklearn\n","y_true = np.array(all_labels)\n","y_pred = np.array(all_preds)\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","\n","# Visualize the confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.show()\n","\n","# Ensure the class names are in the correct order for target_names\n","ordered_class_names = [name for name, num in sorted(loader.sign_to_label.items(), key=lambda item: item[1])]\n","\n","# Per-Class Accuracy\n","class_accuracy = cm.diagonal() / cm.sum(axis=1)\n","for i, acc in enumerate(class_accuracy):\n","    class_name = ordered_class_names[i]\n","    print(f\"Accuracy for class {i} ({class_name}): {acc*100:.2f}%\")\n","\n","# Detailed classification report\n","print(\"\\nClassification Report:\\n\")\n","print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hl5tQmtN9Syt"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def print_top_misclassified_classes(y_true, y_pred, sign_to_label, N=3, zero_division=1):\n","    \"\"\"\n","    Prints the top N classes that get misclassified the most.\n","\n","    Parameters:\n","    - y_true: Actual labels\n","    - y_pred: Predicted labels by the model\n","    - sign_to_label: Dictionary mapping class names to class numbers\n","    - N: Number of top misclassified classes to print\n","    - zero_division: Parameter for handling zero division in classification_report\n","\n","    Returns:\n","    None\n","    \"\"\"\n","\n","    # Ensure the class names are in the correct order for target_names\n","    ordered_class_names = [name for name, num in sorted(sign_to_label.items(), key=lambda item: item[1])]\n","\n","    # Generate and print classification report with class names\n","    print(\"\\nClassification Report:\\n\")\n","    print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=zero_division))\n","\n","    # Generate classification report as dict to find misclassified classes\n","    report = classification_report(y_true, y_pred, output_dict=True, zero_division=zero_division)\n","\n","    # Create a dictionary to store misclassification rates\n","    misclassification_rates = {}\n","\n","    # Iterate through each class in the report\n","    for class_num, metrics in report.items():\n","        if class_num.isdigit():\n","            class_name = [key for key, value in sign_to_label.items() if value == int(class_num)][0]\n","            misclassification_rates[class_name] = 1 - metrics['recall']\n","\n","    # Sort classes based on misclassification rate\n","    sorted_classes = sorted(misclassification_rates, key=misclassification_rates.get, reverse=True)\n","\n","    # Print top N misclassified classes\n","    print(f\"\\nTop {N} misclassified classes:\")\n","    for i in range(N):\n","        class_name = sorted_classes[i]\n","        print(f\"{i+1}. {class_name} - Misclassification rate: {misclassification_rates[class_name]:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4ZtqFxz9XlG"},"outputs":[],"source":["print_top_misclassified_classes(y_true, y_pred, loader.sign_to_label, N=10, zero_division=1)"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"1wIPH3B0fuuoSlPfXK5fGd9Em1LP-uQFJ","timestamp":1697014386160}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}