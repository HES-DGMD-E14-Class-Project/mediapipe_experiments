{"cells":[{"cell_type":"markdown","metadata":{"id":"lLqJy6EZtrZB"},"source":["### Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7-ewruGCyaCn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701202590300,"user_tz":420,"elapsed":23097,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"2e4fdc9e-c645-49e9-b3aa-961ce4701d8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"yLRvBRGgt5Zk"},"source":["#### Install Pytorch Geometric Temporal"]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"id":"QRkM-wvTVBMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701202596280,"user_tz":420,"elapsed":5984,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"c8c55cae-b5bc-47b4-9c27-6e968473d49a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n","Installing collected packages: torch_geometric\n","Successfully installed torch_geometric-2.4.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oiSS4wuxZ01m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701202613487,"user_tz":420,"elapsed":17210,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"0a4d2f18-bc0a-4fa9-dbcb-592112ad66e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n","Collecting pyg_lib\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/pyg_lib-0.3.1%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (887 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.8/887.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.3)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n","Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n","Successfully installed pyg_lib-0.3.1+pt21cu118 torch_cluster-1.6.3+pt21cu118 torch_scatter-2.1.2+pt21cu118 torch_sparse-0.6.18+pt21cu118 torch_spline_conv-1.2.2+pt21cu118\n"]}],"source":["import torch\n","\n","TORCH = torch.__version__.split('+')[0]\n","CUDA = 'cu' + torch.version.cuda.replace('.', '')\n","\n","# Construct the installation command\n","install_command = f\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\"\n","\n","# Execute the command\n","!{install_command}"]},{"cell_type":"code","source":["import numpy as np\n","import os\n","\n","# Set a random seed for reproducibility\n","torch.manual_seed(42)\n","np.random.seed(42)\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"upFSRna0XWWE","executionInfo":{"status":"ok","timestamp":1701202613800,"user_tz":420,"elapsed":315,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zi7c7EMpsCBX"},"source":["### `ASLDatasetLoader` Class\n","\n","The `ASLDatasetLoader` class is designed for loading and processing the ASL dataset. Given a directory, it reads sign language data from JSON files and constructs graph representations suitable for graph-based neural networks. Crucially, the class converts JSON data into PyTorch Geometric (PyG) `Data` objects comprising `x` (node features), `edge_index` (graph connectivity), and `y' (labels) attributes.\n","\n","**Methods**:\n","\n","- `_create_sign_to_label_map`: Generates a mapping from sign names to unique labels.\n","\n","- `_read_file_data`: Reads data from a given JSON file.\n","\n","- `_augment_data`: Implements data augmentation by applying random rotation, translation, and scaling to landmarks, which can enhance the model's robustness.\n","\n","- `_create_graph_from_frame`: Constructs a PyG `Data` object from frame data, concentrating on hand and face landmarks. Edges are created between consecutive landmarks and between left and right hand landmarks. Additional features, like hand-to-face distances, are also computed.\n","\n","- `get_dataset`: Assembles the dataset, optionally incorporating data augmentation. The function outputs a list of PyG `Data` objects ready for graph neural network processing."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LifBvD3D4t4C","executionInfo":{"status":"ok","timestamp":1701202616687,"user_tz":420,"elapsed":2894,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["import json\n","from torch_geometric.data import Data\n","\n","class ASLDatasetLoader:\n","    # Define natural connections as class attributes\n","    HAND_CONNECTIONS = frozenset([\n","      # Left hand palm\n","      (\"left_hand-0\", \"left_hand-1\"),\n","      (\"left_hand-0\", \"left_hand-5\"),\n","      (\"left_hand-9\", \"left_hand-13\"),\n","      (\"left_hand-13\", \"left_hand-17\"),\n","      (\"left_hand-5\", \"left_hand-9\"),\n","      (\"left_hand-0\", \"left_hand-17\"),\n","      # Left hand thumb\n","      (\"left_hand-1\", \"left_hand-2\"),\n","      (\"left_hand-2\", \"left_hand-3\"),\n","      (\"left_hand-3\", \"left_hand-4\"),\n","      # Left hand index finger\n","      (\"left_hand-5\", \"left_hand-6\"),\n","      (\"left_hand-6\", \"left_hand-7\"),\n","      (\"left_hand-7\", \"left_hand-8\"),\n","      # Left hand middle finger\n","      (\"left_hand-9\", \"left_hand-10\"),\n","      (\"left_hand-10\", \"left_hand-11\"),\n","      (\"left_hand-11\", \"left_hand-12\"),\n","      # Left hand ring finger\n","      (\"left_hand-13\", \"left_hand-14\"),\n","      (\"left_hand-14\", \"left_hand-15\"),\n","      (\"left_hand-15\", \"left_hand-16\"),\n","      # Left hand pinky\n","      (\"left_hand-17\", \"left_hand-18\"),\n","      (\"left_hand-18\", \"left_hand-19\"),\n","      (\"left_hand-19\", \"left_hand-20\"),\n","      # Right hand palm\n","      (\"right_hand-0\", \"right_hand-1\"),\n","      (\"right_hand-0\", \"right_hand-5\"),\n","      (\"right_hand-9\", \"right_hand-13\"),\n","      (\"right_hand-13\", \"right_hand-17\"),\n","      (\"right_hand-5\", \"right_hand-9\"),\n","      (\"right_hand-0\", \"right_hand-17\"),\n","      # Right hand thumb\n","      (\"right_hand-1\", \"right_hand-2\"),\n","      (\"right_hand-2\", \"right_hand-3\"),\n","      (\"right_hand-3\", \"right_hand-4\"),\n","      # Right hand index finger\n","      (\"right_hand-5\", \"right_hand-6\"),\n","      (\"right_hand-6\", \"right_hand-7\"),\n","      (\"right_hand-7\", \"right_hand-8\"),\n","      # Right hand middle finger\n","      (\"right_hand-9\", \"right_hand-10\"),\n","      (\"right_hand-10\", \"right_hand-11\"),\n","      (\"right_hand-11\", \"right_hand-12\"),\n","      # Right hand ring finger\n","      (\"right_hand-13\", \"right_hand-14\"),\n","      (\"right_hand-14\", \"right_hand-15\"),\n","      (\"right_hand-15\", \"right_hand-16\"),\n","      # Right hand pinky\n","      (\"right_hand-17\", \"right_hand-18\"),\n","      (\"right_hand-18\", \"right_hand-19\"),\n","      (\"right_hand-19\", \"right_hand-20\"),\n","    ])\n","\n","    POSE_CONNECTIONS = frozenset([\n","      (\"pose-0\", \"pose-1\"),\n","      (\"pose-1\", \"pose-2\"),\n","      (\"pose-2\", \"pose-3\"),\n","      (\"pose-3\", \"pose-7\"),\n","      (\"pose-0\", \"pose-4\"),\n","      (\"pose-4\", \"pose-5\"),\n","      (\"pose-5\", \"pose-6\"),\n","      (\"pose-6\", \"pose-8\"),\n","      (\"pose-9\", \"pose-10\"),\n","      (\"pose-11\", \"pose-12\"),\n","      (\"pose-11\", \"pose-13\"),\n","      (\"pose-13\", \"pose-15\"),\n","      (\"pose-15\", \"pose-17\"),\n","      (\"pose-12\", \"pose-14\"),\n","      (\"pose-14\", \"pose-16\"),\n","      (\"pose-16\", \"pose-18\"),\n","      (\"pose-11\", \"pose-23\"),\n","      (\"pose-12\", \"pose-24\"),\n","      (\"pose-23\", \"pose-24\"),\n","    ])\n","\n","    FACE_CONNECTIONS = frozenset([\n","      # Connections for FACEMESH_LIPS using available landmarks\n","      (\"face-61\", \"face-146\"), (\"face-146\", \"face-91\"), (\"face-91\", \"face-181\"),\n","      (\"face-181\", \"face-84\"), (\"face-84\", \"face-17\"), (\"face-17\", \"face-314\"),\n","      (\"face-314\", \"face-405\"), (\"face-405\", \"face-321\"), (\"face-321\", \"face-375\"),\n","      (\"face-375\", \"face-291\"), (\"face-78\", \"face-95\"), (\"face-95\", \"face-88\"),\n","      (\"face-88\", \"face-178\"), (\"face-178\", \"face-87\"), (\"face-87\", \"face-14\"),\n","      (\"face-14\", \"face-317\"), (\"face-317\", \"face-402\"), (\"face-402\", \"face-318\"),\n","      (\"face-318\", \"face-324\"), (\"face-324\", \"face-308\"),\n","\n","      # Connections for FACEMESH_LEFT_EYE using available landmarks\n","      (\"face-263\", \"face-249\"), (\"face-388\", \"face-387\"), (\"face-387\", \"face-386\"),\n","      (\"face-386\", \"face-385\"), (\"face-385\", \"face-384\"), (\"face-384\", \"face-398\"),\n","\n","      # Connections for FACEMESH_LEFT_EYEBROW using available landmarks\n","      (\"face-276\", \"face-283\"), (\"face-300\", \"face-293\"), (\"face-293\", \"face-334\"),\n","      (\"face-334\", \"face-296\"), (\"face-296\", \"face-336\"),\n","\n","      # Connections for FACEMESH_RIGHT_EYE using available landmarks\n","      (\"face-33\", \"face-7\"), (\"face-246\", \"face-161\"), (\"face-161\", \"face-160\"),\n","      (\"face-160\", \"face-159\"), (\"face-159\", \"face-158\"), (\"face-158\", \"face-157\"),\n","      (\"face-157\", \"face-173\"),\n","\n","      # Connections for FACEMESH_RIGHT_EYEBROW using available landmarks\n","      (\"face-46\", \"face-53\"), (\"face-70\", \"face-63\"), (\"face-63\", \"face-105\"),\n","      (\"face-105\", \"face-66\"), (\"face-66\", \"face-107\"),\n","\n","      # Connections for FACEMESH_FACE_OVAL using available landmarks\n","      (\"face-10\", \"face-338\"), (\"face-338\", \"face-297\"), (\"face-297\", \"face-332\"),\n","      (\"face-332\", \"face-284\"), (\"face-284\", \"face-251\"), (\"face-251\", \"face-389\"),\n","      (\"face-389\", \"face-356\"), (\"face-356\", \"face-454\"), (\"face-454\", \"face-323\"),\n","      (\"face-323\", \"face-361\"), (\"face-361\", \"face-288\"), (\"face-288\", \"face-397\"),\n","      (\"face-397\", \"face-365\"), (\"face-365\", \"face-379\"), (\"face-379\", \"face-378\"),\n","      (\"face-378\", \"face-400\"), (\"face-400\", \"face-377\"), (\"face-377\", \"face-152\"),\n","      (\"face-152\", \"face-148\"), (\"face-148\", \"face-176\"), (\"face-176\", \"face-149\"),\n","      (\"face-149\", \"face-150\"), (\"face-150\", \"face-136\"), (\"face-136\", \"face-172\"),\n","      (\"face-172\", \"face-58\"), (\"face-58\", \"face-132\"), (\"face-132\", \"face-93\"),\n","      (\"face-93\", \"face-234\"), (\"face-234\", \"face-127\"), (\"face-127\", \"face-162\"),\n","      (\"face-162\", \"face-21\"), (\"face-21\", \"face-54\"), (\"face-54\", \"face-103\"),\n","      (\"face-103\", \"face-67\"), (\"face-67\", \"face-109\"), (\"face-109\", \"face-10\"),\n","    ])\n","\n","    def __init__(self, directory_path, min_examples_per_class=2, max_files=-1):\n","        self.directory_path = directory_path\n","        self.min_examples_per_class = min_examples_per_class\n","        self.max_files = max_files\n","        self.sign_to_label = self._create_sign_to_label_map()\n","\n","    def _create_sign_to_label_map(self):\n","        signs = [os.path.splitext(filename)[0] for filename in os.listdir(self.directory_path)]\n","        return {sign: i for i, sign in enumerate(signs)}\n","\n","    def _read_file_data(self, file_path):\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","\n","        sign_name = data[\"sign\"]\n","        num_examples = len(data[\"examples\"])\n","        print(f\"Loaded sign '{sign_name}' with {num_examples} examples\")\n","\n","        return data if num_examples >= self.min_examples_per_class else None\n","\n","\n","    def _augment_data(frame_data, rotation_range=10, translation_range=0.05, scaling_range=0.1):\n","        \"\"\"\n","        Augment the frame data with random rotation, translation, and scaling.\n","\n","        :param frame_data: Dictionary containing frame landmarks and deltas.\n","        :param rotation_range: Maximum rotation angle in degrees.\n","        :param translation_range: Maximum translation as a fraction of landmark range.\n","        :param scaling_range: Maximum scaling factor.\n","        :return: Augmented frame data.\n","        \"\"\"\n","        # Extract landmarks\n","        landmarks = np.array([[landmark['x'], landmark['y']] for landmark in frame_data['landmarks']])\n","        centroid = np.mean(landmarks, axis=0)\n","\n","        # Random rotation\n","        theta = np.radians(np.random.uniform(-rotation_range, rotation_range))\n","        rotation_matrix = np.array([\n","            [np.cos(theta), -np.sin(theta)],\n","            [np.sin(theta), np.cos(theta)]\n","        ])\n","        landmarks = np.dot(landmarks - centroid, rotation_matrix) + centroid\n","\n","        # Random translation\n","        max_translation = translation_range * (landmarks.max(axis=0) - landmarks.min(axis=0))\n","        translations = np.random.uniform(-max_translation, max_translation, size=landmarks.shape[1])\n","        landmarks += translations\n","\n","        # Random scaling\n","        scale = np.random.uniform(1 - scaling_range, 1 + scaling_range)\n","        landmarks = centroid + scale * (landmarks - centroid)\n","\n","        # Update the landmarks in frame_data\n","        for i, landmark in enumerate(frame_data['landmarks']):\n","            landmark['x'], landmark['y'] = landmarks[i]\n","\n","        return frame_data\n","\n","    def _create_graph_from_frame(self, sign_name, sign_data):\n","        graphs = []\n","\n","        for example in sign_data[\"examples\"]:\n","            all_features = []  # Combined list for landmarks, velocities, and accelerations\n","            edges = []\n","\n","            for frame in example[\"frames\"]:\n","                for landmark_data in frame[\"landmarks\"]:\n","                    # Extract spatial coordinates\n","                    landmark_features = [landmark_data[\"x\"], landmark_data[\"y\"]]\n","\n","                    # Extract temporal data (velocity and acceleration)\n","                    temporal_data = next((item for item in frame[\"temporal\"] if item[\"landmark\"] == landmark_data[\"landmark\"]), None)\n","                    if temporal_data:\n","                        velocity = [temporal_data[\"velocity\"][\"x\"], temporal_data[\"velocity\"][\"y\"]]\n","                        acceleration = [temporal_data[\"acceleration\"][\"x\"], temporal_data[\"acceleration\"][\"y\"]]\n","                    else:\n","                        velocity = [0, 0]\n","                        acceleration = [0, 0]\n","\n","                    # Combine spatial and temporal features\n","                    combined_features = landmark_features + velocity + acceleration\n","                    all_features.append(combined_features)\n","\n","                # Add spatial edges within the frame using natural connections\n","                for i in range(len(frame[\"landmarks\"])):\n","                    for j in range(len(frame[\"landmarks\"])):\n","                        if i != j:\n","                            connection = (frame[\"landmarks\"][i][\"landmark\"], frame[\"landmarks\"][j][\"landmark\"])\n","                            if connection in self.HAND_CONNECTIONS or \\\n","                              connection in self.POSE_CONNECTIONS or \\\n","                              connection in self.FACE_CONNECTIONS:\n","                                edges.append([len(all_features) - len(frame[\"landmarks\"]) + i,\n","                                              len(all_features) - len(frame[\"landmarks\"]) + j])\n","\n","            # Add temporal edges between frames within each example\n","            for i in range(len(example[\"frames\"]) - 1):\n","                for j in range(len(frame[\"landmarks\"])):\n","                    start_index = i * len(frame[\"landmarks\"]) + j\n","                    end_index = (i + 1) * len(frame[\"landmarks\"]) + j\n","                    edges.append([start_index, end_index])\n","\n","            # Create the graph\n","            x = torch.tensor(all_features, dtype=torch.float)\n","            edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n","            y = torch.tensor([self.sign_to_label[sign_name]], dtype=torch.long)\n","\n","            # Append the graph for the current example to the list of graphs\n","            graphs.append(Data(x=x, edge_index=edge_index, y=y))\n","\n","        return graphs\n","\n","    def get_dataset(self, augment=False):\n","        dataset = []\n","        file_count = 0\n","\n","        for filename in os.listdir(self.directory_path):\n","            if 0 <= self.max_files <= file_count:\n","                break  # Stop if max_files limit is reached\n","\n","            sign_name = os.path.splitext(filename)[0]\n","            file_path = os.path.join(self.directory_path, filename)\n","            sign_data = self._read_file_data(file_path)\n","            file_count += 1\n","\n","            if sign_data is None:\n","                print(f\"Skipping sign '{sign_name}' due to insufficient examples\")\n","                continue\n","\n","            # Retrieve a list of graphs, one for each example\n","            graphs = self._create_graph_from_frame(sign_name, sign_data)\n","\n","            # Debugging: Check the number of graphs created for the current sign\n","            print(f\"Sign '{sign_name}': Created {len(graphs)} graphs\")\n","\n","            dataset.extend(graphs)  # Extend the dataset with the list of graphs\n","\n","        return dataset\n","\n","    def number_of_classes(self):\n","        return len(self.sign_to_label)"]},{"cell_type":"markdown","metadata":{"id":"xooW2sogtdL1"},"source":["### `ASLGraphClassifier` Class\n","\n","The `ASLGraphClassifier`, features deeper GCN layers and additional channels to capture intricate data patterns potentially. It takes a PyG `Data` object as input, and its forward pass emits class logits.\n","\n","**Methods**:\n","\n","- `forward`: Details the forward pass, accepting a PyG `Data` object. Two GCN layers with subsequent batch normalization and dropout layers process the input. Post global max-pooling, two linear layers coupled with dropout ensure final classification, leading to log-softmax outputs."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RAslUK79VVV6","executionInfo":{"status":"ok","timestamp":1701202616687,"user_tz":420,"elapsed":5,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, global_max_pool, global_mean_pool\n","\n","class ASLGraphClassifier(torch.nn.Module):\n","    def __init__(self, num_features, num_classes):\n","        super(ASLGraphClassifier, self).__init__()\n","        self.conv1 = GCNConv(num_features, 1024)  # Increased channels\n","        self.bn1 = torch.nn.BatchNorm1d(1024)    # Batch normalization layer\n","        self.conv2 = GCNConv(1024, 2048)          # Increased channels\n","        self.bn2 = torch.nn.BatchNorm1d(2048)    # Batch normalization layer\n","        self.lin1 = torch.nn.Linear(2048, 1024)\n","        self.lin2 = torch.nn.Linear(1024, num_classes)\n","        self.dropout = torch.nn.Dropout(p=0.4)\n","\n","    def forward(self, data):\n","        x, edge_index, batch = data.x, data.edge_index, data.batch\n","        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n","        x = self.dropout(x)\n","        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n","        x = self.dropout(x)\n","        x = global_max_pool(x, batch)\n","        x = F.relu(self.lin1(x))\n","        x = self.dropout(x)\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"RdBGsFveWcbF","executionInfo":{"status":"ok","timestamp":1701202617528,"user_tz":420,"elapsed":845,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch_geometric.loader import DataLoader\n","from collections import Counter\n","import random\n","\n","EPOCHS = 100\n","LEARNING_RATE = 0.0001\n","\n","\n","def stratified_data_split(data_list, test_size=0.2):\n","    \"\"\"\n","    This function splits a dataset into training and testing subsets, preserving\n","    the class distribution by leveraging the stratification capabilities of\n","    `train_test_split` from `sklearn`. Stratification helps with potential class\n","    imbalances.\n","    \"\"\"\n","    # Extract labels from data list\n","    labels = [data.y.item() for data in data_list]\n","\n","    # Use sklearn's train_test_split with stratify option\n","    train_data, test_data = train_test_split(data_list, test_size=test_size, stratify=labels, random_state=42)\n","\n","    return train_data, test_data\n","\n","\n","def validate(loader, model, device):\n","    \"\"\"\n","    Used to evaluate the model on validation/test data, computing accuracy as a\n","    performance metric, and offering insights into the model's efficacy.\n","    \"\"\"\n","    model.eval()\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        with torch.no_grad():\n","            out = model(data)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred == data.y).sum())\n","    return correct / len(loader.dataset)\n","\n","def train(loader):\n","    \"\"\"\n","    The `train` function establishes the training loop for the graph-based\n","    neural network. It enacts typical training loop tasks like logging\n","    epoch-wise loss, validation, and early stopping.\n","\n","    The function also harnesses schedulers, regularization techniques, and\n","    gradient clipping to ensure smooth and optimal training.\n","    \"\"\"\n","\n","    # Create the entire dataset without augmentation and then perform stratified split\n","    data_list = loader.get_dataset()\n","    train_dataset, test_dataset = stratified_data_split(data_list, test_size=0.2)\n","\n","    # Now augment only the training dataset\n","    augmented_train_dataset = loader.get_dataset(augment=True)\n","\n","    num_classes = loader.number_of_classes()\n","\n","    train_labels = [data.y.item() for data in train_dataset]\n","    test_labels = [data.y.item() for data in test_dataset]\n","\n","    print(\"Training label distribution:\", Counter(train_labels))\n","    print(\"Test label distribution:\", Counter(test_labels))\n","\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    num_features = train_dataset[0].x.size(1)\n","    model = ASLGraphClassifier(num_features=num_features, num_classes=num_classes).to(device)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=10, verbose=True)\n","\n","    max_epochs_without_improvement = 20\n","    epochs_without_improvement = 0\n","    best_val_accuracy = 0\n","\n","    model.train()\n","    for epoch in range(EPOCHS):\n","        total_loss = 0\n","        correct_train = 0\n","        total_train = 0\n","\n","        for batch in train_loader:\n","            batch = batch.to(device)\n","            optimizer.zero_grad()\n","            out = model(batch)\n","            loss = F.nll_loss(out, batch.y)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","            # Calculate training accuracy\n","            pred_train = out.argmax(dim=1)\n","            correct_train += int((pred_train == batch.y).sum())\n","            total_train += batch.y.size(0)\n","\n","            if np.isnan(loss.item()):\n","                print(\"Warning: NaN loss detected!\")\n","\n","        avg_loss = total_loss / len(train_loader)\n","        train_accuracy = correct_train / total_train\n","        val_accuracy = validate(test_loader, model, device)\n","\n","        print(f\"Epoch {epoch}, Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","        scheduler.step(val_accuracy)\n","\n","        if val_accuracy > best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        if epochs_without_improvement >= max_epochs_without_improvement:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","    model.eval()\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for batch in test_loader:\n","        batch = batch.to(device)\n","        with torch.no_grad():\n","            pred = model(batch).max(dim=1)[1]\n","            all_preds.extend(pred.cpu().numpy())\n","            all_labels.extend(batch.y.cpu().numpy())\n","            correct += pred.eq(batch.y).sum().item()\n","\n","    accuracy = correct / len(test_dataset)\n","\n","    print(f\"Accuracy: {accuracy}\")\n","    print(\"Sample predictions:\", all_preds[:20])\n","    print(\"Sample true labels:\", all_labels[:20])\n","\n","    return model, all_preds, all_labels, accuracy\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"rr2PlwLy5M6H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701205018727,"user_tz":420,"elapsed":2401201,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"4afd6485-8d05-46e5-c469-ec013135c6a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded sign 'TV' with 385 examples\n","Sign 'TV': Created 385 graphs\n","Loaded sign 'after' with 347 examples\n","Sign 'after': Created 347 graphs\n","Loaded sign 'airplane' with 393 examples\n","Sign 'airplane': Created 393 graphs\n","Loaded sign 'all' with 386 examples\n","Sign 'all': Created 386 graphs\n","Loaded sign 'alligator' with 390 examples\n","Sign 'alligator': Created 390 graphs\n","Loaded sign 'TV' with 385 examples\n","Sign 'TV': Created 385 graphs\n","Loaded sign 'after' with 347 examples\n","Sign 'after': Created 347 graphs\n","Loaded sign 'airplane' with 393 examples\n","Sign 'airplane': Created 393 graphs\n","Loaded sign 'all' with 386 examples\n","Sign 'all': Created 386 graphs\n","Loaded sign 'alligator' with 390 examples\n","Sign 'alligator': Created 390 graphs\n","Training label distribution: Counter({2: 314, 4: 312, 3: 309, 0: 308, 1: 277})\n","Test label distribution: Counter({2: 79, 4: 78, 3: 77, 0: 77, 1: 70})\n","Epoch 0, Loss: 2.5977, Training Accuracy: 0.2164, Validation Accuracy: 0.2126\n","Epoch 1, Loss: 1.6062, Training Accuracy: 0.2151, Validation Accuracy: 0.2021\n","Epoch 2, Loss: 1.5682, Training Accuracy: 0.2724, Validation Accuracy: 0.2756\n","Epoch 3, Loss: 1.4980, Training Accuracy: 0.3421, Validation Accuracy: 0.3858\n","Epoch 4, Loss: 1.4160, Training Accuracy: 0.4046, Validation Accuracy: 0.4094\n","Epoch 5, Loss: 1.3597, Training Accuracy: 0.4316, Validation Accuracy: 0.4016\n","Epoch 6, Loss: 1.3193, Training Accuracy: 0.4434, Validation Accuracy: 0.4751\n","Epoch 7, Loss: 1.2928, Training Accuracy: 0.4553, Validation Accuracy: 0.4094\n","Epoch 8, Loss: 1.3132, Training Accuracy: 0.4507, Validation Accuracy: 0.4724\n","Epoch 9, Loss: 1.2640, Training Accuracy: 0.4697, Validation Accuracy: 0.4672\n","Epoch 10, Loss: 1.2455, Training Accuracy: 0.4743, Validation Accuracy: 0.4777\n","Epoch 11, Loss: 1.2284, Training Accuracy: 0.4993, Validation Accuracy: 0.5013\n","Epoch 12, Loss: 1.2106, Training Accuracy: 0.5079, Validation Accuracy: 0.5118\n","Epoch 13, Loss: 1.2219, Training Accuracy: 0.5013, Validation Accuracy: 0.5118\n","Epoch 14, Loss: 1.1954, Training Accuracy: 0.5204, Validation Accuracy: 0.4987\n","Epoch 15, Loss: 1.1838, Training Accuracy: 0.5191, Validation Accuracy: 0.4987\n","Epoch 16, Loss: 1.1787, Training Accuracy: 0.5237, Validation Accuracy: 0.5092\n","Epoch 17, Loss: 1.1750, Training Accuracy: 0.5395, Validation Accuracy: 0.4751\n","Epoch 18, Loss: 1.1647, Training Accuracy: 0.5447, Validation Accuracy: 0.5092\n","Epoch 19, Loss: 1.1532, Training Accuracy: 0.5487, Validation Accuracy: 0.4856\n","Epoch 20, Loss: 1.1471, Training Accuracy: 0.5454, Validation Accuracy: 0.5066\n","Epoch 21, Loss: 1.1405, Training Accuracy: 0.5395, Validation Accuracy: 0.4856\n","Epoch 22, Loss: 1.1408, Training Accuracy: 0.5507, Validation Accuracy: 0.5328\n","Epoch 23, Loss: 1.1278, Training Accuracy: 0.5513, Validation Accuracy: 0.5066\n","Epoch 24, Loss: 1.1257, Training Accuracy: 0.5500, Validation Accuracy: 0.5407\n","Epoch 25, Loss: 1.1021, Training Accuracy: 0.5836, Validation Accuracy: 0.5354\n","Epoch 26, Loss: 1.1008, Training Accuracy: 0.5737, Validation Accuracy: 0.5276\n","Epoch 27, Loss: 1.1104, Training Accuracy: 0.5658, Validation Accuracy: 0.5276\n","Epoch 28, Loss: 1.0836, Training Accuracy: 0.5803, Validation Accuracy: 0.5381\n","Epoch 29, Loss: 1.0861, Training Accuracy: 0.5803, Validation Accuracy: 0.5302\n","Epoch 30, Loss: 1.0759, Training Accuracy: 0.5849, Validation Accuracy: 0.5433\n","Epoch 31, Loss: 1.0909, Training Accuracy: 0.5711, Validation Accuracy: 0.5486\n","Epoch 32, Loss: 1.0569, Training Accuracy: 0.6033, Validation Accuracy: 0.5538\n","Epoch 33, Loss: 1.0664, Training Accuracy: 0.5901, Validation Accuracy: 0.5564\n","Epoch 34, Loss: 1.0412, Training Accuracy: 0.6053, Validation Accuracy: 0.5564\n","Epoch 35, Loss: 1.0438, Training Accuracy: 0.6112, Validation Accuracy: 0.5538\n","Epoch 36, Loss: 1.0425, Training Accuracy: 0.6138, Validation Accuracy: 0.5696\n","Epoch 37, Loss: 1.0186, Training Accuracy: 0.6191, Validation Accuracy: 0.5433\n","Epoch 38, Loss: 1.0322, Training Accuracy: 0.6066, Validation Accuracy: 0.5564\n","Epoch 39, Loss: 1.0203, Training Accuracy: 0.6178, Validation Accuracy: 0.5669\n","Epoch 40, Loss: 1.0242, Training Accuracy: 0.6217, Validation Accuracy: 0.5617\n","Epoch 41, Loss: 1.0106, Training Accuracy: 0.6243, Validation Accuracy: 0.5171\n","Epoch 42, Loss: 1.0164, Training Accuracy: 0.6164, Validation Accuracy: 0.5722\n","Epoch 43, Loss: 0.9999, Training Accuracy: 0.6296, Validation Accuracy: 0.5801\n","Epoch 44, Loss: 0.9886, Training Accuracy: 0.6388, Validation Accuracy: 0.5197\n","Epoch 45, Loss: 1.0015, Training Accuracy: 0.6184, Validation Accuracy: 0.5932\n","Epoch 46, Loss: 0.9777, Training Accuracy: 0.6309, Validation Accuracy: 0.5722\n","Epoch 47, Loss: 0.9725, Training Accuracy: 0.6316, Validation Accuracy: 0.5801\n","Epoch 48, Loss: 0.9734, Training Accuracy: 0.6434, Validation Accuracy: 0.5774\n","Epoch 49, Loss: 0.9647, Training Accuracy: 0.6414, Validation Accuracy: 0.5748\n","Epoch 50, Loss: 0.9728, Training Accuracy: 0.6191, Validation Accuracy: 0.5407\n","Epoch 51, Loss: 0.9595, Training Accuracy: 0.6428, Validation Accuracy: 0.5617\n","Epoch 52, Loss: 0.9410, Training Accuracy: 0.6553, Validation Accuracy: 0.5696\n","Epoch 53, Loss: 0.9523, Training Accuracy: 0.6513, Validation Accuracy: 0.5669\n","Epoch 54, Loss: 0.9407, Training Accuracy: 0.6480, Validation Accuracy: 0.5748\n","Epoch 55, Loss: 0.9532, Training Accuracy: 0.6507, Validation Accuracy: 0.5853\n","Epoch 56, Loss: 0.9176, Training Accuracy: 0.6671, Validation Accuracy: 0.5879\n","Epoch 00057: reducing learning rate of group 0 to 7.0000e-05.\n","Epoch 57, Loss: 0.9119, Training Accuracy: 0.6737, Validation Accuracy: 0.5801\n","Epoch 58, Loss: 0.8977, Training Accuracy: 0.6625, Validation Accuracy: 0.5984\n","Epoch 59, Loss: 0.9063, Training Accuracy: 0.6678, Validation Accuracy: 0.5512\n","Epoch 60, Loss: 0.8941, Training Accuracy: 0.6724, Validation Accuracy: 0.6168\n","Epoch 61, Loss: 0.8873, Training Accuracy: 0.6862, Validation Accuracy: 0.5853\n","Epoch 62, Loss: 0.8893, Training Accuracy: 0.6724, Validation Accuracy: 0.5879\n","Epoch 63, Loss: 0.8826, Training Accuracy: 0.6862, Validation Accuracy: 0.5801\n","Epoch 64, Loss: 0.8783, Training Accuracy: 0.6822, Validation Accuracy: 0.6089\n","Epoch 65, Loss: 0.8575, Training Accuracy: 0.7000, Validation Accuracy: 0.5906\n","Epoch 66, Loss: 0.8757, Training Accuracy: 0.6895, Validation Accuracy: 0.5774\n","Epoch 67, Loss: 0.8609, Training Accuracy: 0.6954, Validation Accuracy: 0.5696\n","Epoch 68, Loss: 0.8472, Training Accuracy: 0.6934, Validation Accuracy: 0.6037\n","Epoch 69, Loss: 0.8601, Training Accuracy: 0.6868, Validation Accuracy: 0.5879\n","Epoch 70, Loss: 0.8380, Training Accuracy: 0.7066, Validation Accuracy: 0.6010\n","Epoch 71, Loss: 0.8300, Training Accuracy: 0.7072, Validation Accuracy: 0.5906\n","Epoch 00072: reducing learning rate of group 0 to 4.9000e-05.\n","Epoch 72, Loss: 0.8377, Training Accuracy: 0.7033, Validation Accuracy: 0.5958\n","Epoch 73, Loss: 0.8270, Training Accuracy: 0.7072, Validation Accuracy: 0.5984\n","Epoch 74, Loss: 0.8230, Training Accuracy: 0.7138, Validation Accuracy: 0.6063\n","Epoch 75, Loss: 0.8140, Training Accuracy: 0.7145, Validation Accuracy: 0.6063\n","Epoch 76, Loss: 0.7977, Training Accuracy: 0.7276, Validation Accuracy: 0.6037\n","Epoch 77, Loss: 0.8114, Training Accuracy: 0.7164, Validation Accuracy: 0.6115\n","Epoch 78, Loss: 0.7955, Training Accuracy: 0.7270, Validation Accuracy: 0.5984\n","Epoch 79, Loss: 0.7963, Training Accuracy: 0.7211, Validation Accuracy: 0.6142\n","Epoch 80, Loss: 0.7949, Training Accuracy: 0.7230, Validation Accuracy: 0.6142\n","Early stopping triggered.\n","Accuracy: 0.6141732283464567\n","Sample predictions: [2, 0, 3, 0, 4, 3, 2, 3, 0, 0, 0, 3, 3, 2, 3, 0, 0, 0, 2, 4]\n","Sample true labels: [2, 1, 4, 3, 4, 3, 4, 3, 3, 1, 1, 3, 3, 4, 3, 4, 1, 0, 2, 4]\n"]}],"source":["MAX_FILES = 5\n","directory_path = \"/content/drive/MyDrive/Colab Notebooks/DGMD E-14 Project/Datasets/processed-40-500\"\n","loader = ASLDatasetLoader(directory_path, max_files=MAX_FILES)\n","\n","model, all_preds, all_labels, accuracy = train(loader)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"sMrYkTs89Q7O","colab":{"base_uri":"https://localhost:8080/","height":996},"executionInfo":{"status":"ok","timestamp":1701205019101,"user_tz":420,"elapsed":377,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"bb624b23-4cff-4dbd-f553-9339c91c72d6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x700 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Accuracy for class 0 (TV): 89.61%\n","Accuracy for class 1 (after): 30.00%\n","Accuracy for class 2 (airplane): 70.89%\n","Accuracy for class 3 (all): 63.64%\n","Accuracy for class 4 (alligator): 50.00%\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","          TV       0.57      0.90      0.70        77\n","       after       0.50      0.30      0.37        70\n","    airplane       0.79      0.71      0.75        79\n","         all       0.54      0.64      0.58        77\n","   alligator       0.68      0.50      0.58        78\n","\n","    accuracy                           0.61       381\n","   macro avg       0.62      0.61      0.60       381\n","weighted avg       0.62      0.61      0.60       381\n","\n"]}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import numpy as np\n","\n","# Convert lists to numpy arrays for compatibility with sklearn\n","y_true = np.array(all_labels)\n","y_pred = np.array(all_preds)\n","\n","# Calculate the confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","\n","# Visualize the confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.show()\n","\n","# Ensure the class names are in the correct order for target_names\n","ordered_class_names = [name for name, num in sorted(loader.sign_to_label.items(), key=lambda item: item[1])]\n","\n","# Per-Class Accuracy\n","class_accuracy = cm.diagonal() / cm.sum(axis=1)\n","for i, acc in enumerate(class_accuracy):\n","    class_name = ordered_class_names[i]\n","    print(f\"Accuracy for class {i} ({class_name}): {acc*100:.2f}%\")\n","\n","# Detailed classification report\n","print(\"\\nClassification Report:\\n\")\n","print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=1))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Hl5tQmtN9Syt","executionInfo":{"status":"ok","timestamp":1701205019101,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def print_top_misclassified_classes(y_true, y_pred, sign_to_label, N=3, zero_division=1):\n","    \"\"\"\n","    Prints the top N classes that get misclassified the most.\n","\n","    Parameters:\n","    - y_true: Actual labels\n","    - y_pred: Predicted labels by the model\n","    - sign_to_label: Dictionary mapping class names to class numbers\n","    - N: Number of top misclassified classes to print\n","    - zero_division: Parameter for handling zero division in classification_report\n","\n","    Returns:\n","    None\n","    \"\"\"\n","\n","    # Ensure the class names are in the correct order for target_names\n","    ordered_class_names = [name for name, num in sorted(sign_to_label.items(), key=lambda item: item[1])]\n","\n","    # Generate and print classification report with class names\n","    print(\"\\nClassification Report:\\n\")\n","    print(classification_report(y_true, y_pred, target_names=ordered_class_names, zero_division=zero_division))\n","\n","    # Generate classification report as dict to find misclassified classes\n","    report = classification_report(y_true, y_pred, output_dict=True, zero_division=zero_division)\n","\n","    # Create a dictionary to store misclassification rates\n","    misclassification_rates = {}\n","\n","    # Iterate through each class in the report\n","    for class_num, metrics in report.items():\n","        if class_num.isdigit():\n","            class_name = [key for key, value in sign_to_label.items() if value == int(class_num)][0]\n","            misclassification_rates[class_name] = 1 - metrics['recall']\n","\n","    # Sort classes based on misclassification rate\n","    sorted_classes = sorted(misclassification_rates, key=misclassification_rates.get, reverse=True)\n","\n","    # Print top N misclassified classes\n","    print(f\"\\nTop {N} misclassified classes:\")\n","    for i in range(N):\n","        class_name = sorted_classes[i]\n","        print(f\"{i+1}. {class_name} - Misclassification rate: {misclassification_rates[class_name]:.2f}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"m4ZtqFxz9XlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701205019101,"user_tz":420,"elapsed":10,"user":{"displayName":"Brian Sam-Bodden","userId":"17727095235669976107"}},"outputId":"bfd410ba-9981-4bf5-d3a8-da656b8366c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","          TV       0.57      0.90      0.70        77\n","       after       0.50      0.30      0.37        70\n","    airplane       0.79      0.71      0.75        79\n","         all       0.54      0.64      0.58        77\n","   alligator       0.68      0.50      0.58        78\n","\n","    accuracy                           0.61       381\n","   macro avg       0.62      0.61      0.60       381\n","weighted avg       0.62      0.61      0.60       381\n","\n","\n","Top 5 misclassified classes:\n","1. after - Misclassification rate: 0.70\n","2. alligator - Misclassification rate: 0.50\n","3. all - Misclassification rate: 0.36\n","4. airplane - Misclassification rate: 0.29\n","5. TV - Misclassification rate: 0.10\n"]}],"source":["N = 10 if MAX_FILES > 50 else MAX_FILES\n","print_top_misclassified_classes(y_true, y_pred, loader.sign_to_label, N=N, zero_division=1)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1wIPH3B0fuuoSlPfXK5fGd9Em1LP-uQFJ","timestamp":1697014386160}],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}